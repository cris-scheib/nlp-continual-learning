{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 17:49:45.810048: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 17:49:46.473409: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-21 17:49:47.840727: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-21 17:49:47.840992: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-21 17:49:47.841015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, GRU, Dense, Embedding\n",
    "from keras.utils import  pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "Here we load the data from the `dataset.csv` file (generated in the other script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('data/fraction/dataset-50k-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocabulary():\n",
    "    vocabulary = list()\n",
    "    with open('data/vocab.30K.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            vocabulary.append(line.strip())\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Transform to lower, remove the new line and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_data(data):\n",
    "    return data.str.lower() \n",
    "    \n",
    "def clean_data(data):\n",
    "    return data.str.replace(',', ' ,')                \\\n",
    "                .str.replace('.',' . ', regex=False)  \\\n",
    "                .str.replace('?',' ?', regex=False)   \\\n",
    "                .str.replace(r\"[^a-zA-Z0-9?'.,]+\",' ',regex=True)\n",
    "\n",
    "def get_data():\n",
    "    data = load_data()\n",
    "    for column in data.columns:    \n",
    "        data[column] = lower_data(data[column])\n",
    "        data[column] = clean_data(data[column])\n",
    "    return shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Mean sentence length and standard deviation of sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_analysis(data):\n",
    "    print('Central tendency, dispersion and shape of questions’s distribution')\n",
    "    print(data['question'].str.len().describe().apply(lambda x: format(x, 'f')))\n",
    "    print('-'*100)\n",
    "    print('Central tendency, dispersion and shape of answers’s distribution')\n",
    "    print(data['answer'].str.len().describe().apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_data_analysis(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data):\n",
    "    return data[(data['question'].str.len() < 100) & (data['answer'].str.len() < 200)]\n",
    "\n",
    "def padd_data(data):\n",
    "    data = data.assign(question = '<start> ' + data.question  + ' <end>')\n",
    "    data = data.assign(answer = '<start> ' + data.answer  + ' <end>')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Convert the unicode sequence to ascii\n",
    "def unicode_to_ascii(s):\n",
    "\n",
    "    # Normalize the unicode string and remove the non-spacking mark\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Preprocess the sequence\n",
    "def preprocess_sentence(w):\n",
    "\n",
    "    # Clean the sequence\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # Create a space between word and the punctuation following it\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # Replace everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # Add a start and stop token to detect the start and end of the sequence\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "Removing the outliers and adding <start> and <end> for each question, awnser pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(num_examples):\n",
    "    dataset = remove_outliers(get_data())\n",
    "    dataset = padd_data(dataset)\n",
    "    return dataset['question'].tolist(), dataset['answer'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing \n",
    "Tokenize the data, padd the sequence and create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenize(vocabulary):\n",
    "    tokenizer = Tokenizer(filters='!\"#$%&()*+-:;=@[\\\\]^_{|}~\\t')\n",
    "  \n",
    "    # Convert sequences into internal vocab\n",
    "    tokenizer.fit_on_texts(vocabulary)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer):\n",
    "\n",
    "    # Convert internal vocab to numbers\n",
    "    tensor = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "    # Pad the tensors to assign equal length to all the sequences\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', truncating='post',maxlen=None)\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the clean and formated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(num_examples=None):\n",
    " \n",
    "    questions, answers = create_dataset(num_examples=None)\n",
    "    vocabulary = load_vocabulary()\n",
    "    \n",
    "    #Create the tokenizer for inputs and outputs\n",
    "    tokenizer = load_tokenize(vocabulary)\n",
    "    \n",
    "    questions_tensor = tokenize(questions, tokenizer)\n",
    "    answers_tensor = tokenize(answers, tokenizer)\n",
    "\n",
    "    return questions_tensor, answers_tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_tensor, answers_tensor, tokenizer = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test\n",
    "Split 80% of the data to train and 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test count: 373\n",
      "Train count: 94\n"
     ]
    }
   ],
   "source": [
    "max_length_input, max_length_target = questions_tensor.shape[1], answers_tensor.shape[1]\n",
    "input_train, input_test, target_train, target_test = train_test_split(questions_tensor, answers_tensor, test_size=0.2)\n",
    "\n",
    "print(\"Test count:\", len(input_train))\n",
    "print(\"Train count:\", len(input_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question; index to word mapping\n",
      "1132 ----> <start>\n",
      "1140 ----> how\n",
      "68 ----> the\n",
      "1282 ----> hell\n",
      "113 ----> do\n",
      "111 ----> i\n",
      "118 ----> make\n",
      "2680 ----> soft\n",
      "3272 ----> cookies\n",
      "172 ----> ?\n",
      "1133 ----> <end>\n",
      "\n",
      "Target awnser; index to word mapping\n",
      "1132 ----> <start>\n",
      "375 ----> use\n",
      "1251 ----> instead\n",
      "112 ----> of\n",
      "1914 ----> butter\n",
      "172 ----> ?\n",
      "1133 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(text, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, text.index_word[t]))\n",
    "      \n",
    "print(\"Input question; index to word mapping\")\n",
    "convert(tokenizer, input_train[0])\n",
    "print()\n",
    "print(\"Target awnser; index to word mapping\")\n",
    "convert(tokenizer, target_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_input_size = len(tokenizer.word_index) + 1\n",
    "vocab_target_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 17:49:49.854931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:50.171013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:50.171213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:50.172127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 17:49:50.172576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:50.172778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:50.172911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:51.484790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:51.485139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:51.485410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-21 17:49:51.485613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3108 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 24]), TensorShape([64, 44]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "\n",
    "        # Embed the vocab to a dense embedding \n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # GRU Layer\n",
    "        # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n",
    "        # used for the linear transformation of the recurrent state\n",
    "        self.gru = GRU(self.encoder_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # Encoder network comprises an Embedding layer followed by a GRU layer\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    # To initialize the hidden state\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 17:49:53.503340: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 24, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Mechanism\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # Used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # x shape == (batch_size, 1)\n",
    "        # hidden shape == (batch_size, max_length)\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "        # context_vector shape == (batch_size, hidden_size)\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 28533)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_target_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer and loss functions\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# Loss function\n",
    "def loss_function(real, pred):\n",
    "\n",
    "    # Take care of the padding. Not all sequences are of equal length.\n",
    "    # If there's a '0' in the sequence, the loss is being nullified\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    # tf.GradientTape() -- record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        # dec_hidden is used by attention, hence is the same enc_hidden\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        # <start> token is the initial decoder input\n",
    "        dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "\n",
    "            # Pass enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Use teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    # As this function is called per batch, compute the batch_loss\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    # Get the model's variables\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    # Compute the gradients\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    # Update the variables of the model/network\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f91c253c2e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.4979\n",
      "Epoch 1 Loss 2.3924\n",
      "Time taken for 1 epoch 203.40997314453125 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.3229\n",
      "Epoch 2 Loss 2.3181\n",
      "Time taken for 1 epoch 133.4827184677124 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.4792\n",
      "Epoch 3 Loss 2.2395\n",
      "Time taken for 1 epoch 164.05353045463562 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.2775\n",
      "Epoch 4 Loss 2.2867\n",
      "Time taken for 1 epoch 151.63573503494263 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.4342\n",
      "Epoch 5 Loss 2.1760\n",
      "Time taken for 1 epoch 143.0168318748474 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.3586\n",
      "Epoch 6 Loss 2.2478\n",
      "Time taken for 1 epoch 176.34069085121155 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.4105\n",
      "Epoch 7 Loss 2.1938\n",
      "Time taken for 1 epoch 196.98840999603271 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.6065\n",
      "Epoch 8 Loss 2.2170\n",
      "Time taken for 1 epoch 168.7911901473999 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.8804\n",
      "Epoch 9 Loss 2.2511\n",
      "Time taken for 1 epoch 160.08805871009827 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 2.3509\n",
      "Epoch 10 Loss 2.2016\n",
      "Time taken for 1 epoch 147.37851405143738 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.3516\n",
      "Epoch 11 Loss 2.2300\n",
      "Time taken for 1 epoch 143.86812114715576 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 2.2576\n",
      "Epoch 12 Loss 2.2236\n",
      "Time taken for 1 epoch 167.82471919059753 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 2.2300\n",
      "Epoch 13 Loss 2.1530\n",
      "Time taken for 1 epoch 143.51681637763977 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.2913\n",
      "Epoch 14 Loss 2.1735\n",
      "Time taken for 1 epoch 159.8510081768036 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.9699\n",
      "Epoch 15 Loss 2.0774\n",
      "Time taken for 1 epoch 142.62623572349548 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.1307\n",
      "Epoch 16 Loss 2.1192\n",
      "Time taken for 1 epoch 164.66786551475525 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.0091\n",
      "Epoch 17 Loss 2.0911\n",
      "Time taken for 1 epoch 144.9520390033722 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.3093\n",
      "Epoch 18 Loss 2.0685\n",
      "Time taken for 1 epoch 172.76985216140747 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.2058\n",
      "Epoch 19 Loss 2.0523\n",
      "Time taken for 1 epoch 142.35712885856628 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.0313\n",
      "Epoch 20 Loss 2.0375\n",
      "Time taken for 1 epoch 170.27810645103455 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.1127\n",
      "Epoch 21 Loss 2.0834\n",
      "Time taken for 1 epoch 168.4674940109253 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 1.8593\n",
      "Epoch 22 Loss 2.0425\n",
      "Time taken for 1 epoch 144.34895181655884 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.0337\n",
      "Epoch 23 Loss 1.9892\n",
      "Time taken for 1 epoch 176.827618598938 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 1.9685\n",
      "Epoch 24 Loss 2.0173\n",
      "Time taken for 1 epoch 144.75277018547058 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 1.9553\n",
      "Epoch 25 Loss 1.9966\n",
      "Time taken for 1 epoch 162.27369904518127 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 2.0110\n",
      "Epoch 26 Loss 2.0202\n",
      "Time taken for 1 epoch 143.61494541168213 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 2.0781\n",
      "Epoch 27 Loss 2.0174\n",
      "Time taken for 1 epoch 169.30210709571838 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 1.7628\n",
      "Epoch 28 Loss 2.0012\n",
      "Time taken for 1 epoch 143.86814856529236 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 2.1206\n",
      "Epoch 29 Loss 2.0365\n",
      "Time taken for 1 epoch 167.66048622131348 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 1.8821\n",
      "Epoch 30 Loss 1.9578\n",
      "Time taken for 1 epoch 147.25318431854248 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 30\n",
    "\n",
    "# Training loop\n",
    "with tf.device('/cpu:0'):\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Loop through the dataset\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "\n",
    "            # Call the train method\n",
    "            batch_loss = train_step(inp, targ, enc_hidden)\n",
    "\n",
    "            # Compute the loss (per batch)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "\n",
    "        # Save (checkpoint) the model every 2 epochs\n",
    "        #if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        # Output the loss observed until that epoch\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate function -- similar to the training loop\n",
    "def evaluate(sentence):\n",
    "\n",
    "    # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n",
    "    attention_plot = np.zeros((max_length_target, max_length_input))\n",
    "\n",
    "    # Preprocess the sentence given\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # Fetch the indices concerning the words in the sentence and pad the sequence\n",
    "    inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_input,\n",
    "                                                         padding='post')\n",
    "    # Convert the inputs to tensors\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    # Loop until the max_length is reached for the target lang (ENGLISH)\n",
    "    for t in range(max_length_target):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        \n",
    "        # Store the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        # Get the prediction with the maximum attention\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        # Append the token to the result\n",
    "        result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        # If <end> token is reached, return the result, input, and attention plot\n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # The predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate function (which internally calls the evaluate function)\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted awnser: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f8ff863e080>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hello . <end>\n",
      "Predicted awnser: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5251/1023563476.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_5251/1023563476.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Hello.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
