{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 16:46:33.950286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 16:46:34.777161: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-26 16:46:36.135878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-26 16:46:36.136231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-26 16:46:36.136265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Vocabulary\n",
    "\n",
    "First, we build the vocabulary dictionaries for the source and target. \n",
    "The vocabulary is the the file `vocab.txt` (generated in the other script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: [('<unk>', 0), ('<s>', 1), ('</s>', 2), ('.', 3), ('the', 4), (',', 5), ('a', 6), ('?', 7), ('to', 8), ('you', 9)]\n",
      "Reverse dictionary: [(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, '.'), (4, 'the'), (5, ','), (6, 'a'), (7, '?'), (8, 'to'), (9, 'you')]\n",
      "Vocabulary size:  30000\n"
     ]
    }
   ],
   "source": [
    "# Word string -> ID mapping\n",
    "dictionary = dict()\n",
    "\n",
    "with open('data/vocab.30K.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # disregard the new line aka `\\n`\n",
    "        dictionary[line[:-1]] = len(dictionary)\n",
    "        \n",
    "reverse_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
    "\n",
    "print('Dictionary:', list(dictionary.items())[:10], end = '\\n')\n",
    "print('Reverse dictionary:', list(reverse_dictionary.items())[:10], end = '\\n')\n",
    "print('Vocabulary size: ', len(dictionary), end = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "Here we load the data from the `dataset.csv` file (generated in the other script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Transform to lower, remove the new line and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerDataset(data):\n",
    "    return data.str.lower() \n",
    "    \n",
    "def cleanDataset(data):\n",
    "    return data.str.replace('/r/','')                  \\\n",
    "                .str.replace(')','', regex=False)      \\\n",
    "                .str.replace('(','', regex=False)      \\\n",
    "                .str.replace(']','', regex=False)      \\\n",
    "                .str.replace('[','', regex=False)      \\\n",
    "                .str.replace('!','')                   \\\n",
    "                .str.replace('\"','')                   \\\n",
    "    \n",
    "def paddDataset(data):\n",
    "    return data.str.replace(',', ' ,')                 \\\n",
    "                .str.replace('.',' . ', regex=False)    \\\n",
    "                .str.replace('?',' ?', regex=False)    \\\n",
    "                .str.replace('\\n',' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = nltk.tokenize.WhitespaceTokenizer()\n",
    "for column in dataset.columns:    \n",
    "    dataset[column] = lowerDataset(dataset[column]) \n",
    "    dataset[column] = cleanDataset(dataset[column])\n",
    "    dataset[column] = paddDataset(dataset[column])                                    \n",
    "    dataset[column] = dataset[column].apply(wt.tokenize)\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138950</th>\n",
       "      <td>[my, 7, year, old, son, told, me, a, single, f...</td>\n",
       "      <td>[i, am, female, genetically, and, by, self-ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348445</th>\n",
       "      <td>[what's, something, that's, universally, attra...</td>\n",
       "      <td>[good, hygiene, ,, being, a, healthy, weight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055434</th>\n",
       "      <td>[what, is, reddit, to, you, ?, is, it, a, plac...</td>\n",
       "      <td>[a, substitute, for, having, friends, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106171</th>\n",
       "      <td>[what, will, happen, in, 2021, ,, are, you, ho...</td>\n",
       "      <td>[i'm, still, cynical, about, 2021, ., it's, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941625</th>\n",
       "      <td>[what's, the, most, insane, thing, an, ex, has...</td>\n",
       "      <td>[she, lived, in, an, apartment, ., right, outs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  question  \\\n",
       "138950   [my, 7, year, old, son, told, me, a, single, f...   \n",
       "348445   [what's, something, that's, universally, attra...   \n",
       "1055434  [what, is, reddit, to, you, ?, is, it, a, plac...   \n",
       "106171   [what, will, happen, in, 2021, ,, are, you, ho...   \n",
       "941625   [what's, the, most, insane, thing, an, ex, has...   \n",
       "\n",
       "                                                    answer  \n",
       "138950   [i, am, female, genetically, and, by, self-ide...  \n",
       "348445   [good, hygiene, ,, being, a, healthy, weight, ...  \n",
       "1055434           [a, substitute, for, having, friends, .]  \n",
       "106171   [i'm, still, cynical, about, 2021, ., it's, go...  \n",
       "941625   [she, lived, in, an, apartment, ., right, outs...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Mean sentence length and standard deviation of sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central tendency, dispersion and shape of questions’s distribution\n",
      "count    1149819.000000\n",
      "mean          17.113906\n",
      "std            9.139078\n",
      "min            1.000000\n",
      "25%           11.000000\n",
      "50%           15.000000\n",
      "75%           21.000000\n",
      "max           82.000000\n",
      "Name: question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Central tendency, dispersion and shape of questions’s distribution')\n",
    "print(dataset['question'].str.len().describe().apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central tendency, dispersion and shape of answers’s distribution\n",
      "count    1149819.000000\n",
      "mean          54.452828\n",
      "std          844.371854\n",
      "min            0.000000\n",
      "25%           10.000000\n",
      "50%           22.000000\n",
      "75%           53.000000\n",
      "max       563680.000000\n",
      "Name: answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Central tendency, dispersion and shape of answers’s distribution')\n",
    "print(dataset['answer'].str.len().describe().apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the sentences to fixed length\n",
    "Update all sentences with a fixed size, to process the sentences as batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_length = {'question' : 30, 'answer': 60}\n",
    "\n",
    "def padding_sent(source):\n",
    "    padded = []\n",
    "    for tokens in dataset[source]: \n",
    "        # adding the start token\n",
    "        tokens.insert(0, '<s>')  \n",
    "\n",
    "        if len(tokens) >= max_sent_length[source]:\n",
    "            tokens = tokens[:(max_sent_length[source] - 1)]\n",
    "            tokens.append('</s>')\n",
    "\n",
    "        if len(tokens) < max_sent_length[source]:\n",
    "            tokens.extend(['</s>' for _ in range(max_sent_length[source] - len(tokens))])  \n",
    "\n",
    "        padded.append(tokens)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = padding_sent('question')\n",
    "answers = padding_sent('answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the reverse dataset\n",
    "The reverse dataset are going to be used to retrieve the decoder output to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reverse_dataset(source):\n",
    "    reverse_tokens = []\n",
    "    reverse_dataset = []\n",
    "    for tokens in source: \n",
    "        for token in tokens: \n",
    "            if token not in dictionary.keys():\n",
    "                reverse_tokens.append(dictionary['<unk>'])\n",
    "            else:\n",
    "                reverse_tokens.append(dictionary[token])\n",
    "        reverse_dataset.append(reverse_tokens)\n",
    "        reverse_tokens = []\n",
    "    return reverse_dataset\n",
    "\n",
    "inputs_indexes =  np.array(create_reverse_dataset(questions), dtype=np.int32)\n",
    "outputs_indexes =  np.array(create_reverse_dataset(answers), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "Use the Word2Vec to embed the input to a hight demention vector, that will keep the word relationships "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learns all the Word2Vec relationships fo the questions, answers and unkown words\n",
    "This code needs to be run just once\n",
    "\"\"\"\n",
    "\n",
    "model = Word2Vec(questions + answers + [['<unk>']], vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formating the inputs and outputs\n",
    "\n",
    "The dataset original format for inputs is 30x100 and for the outputs is 60x30000 for 1.149 million records, making the memory usage impracticable.\n",
    "\n",
    "The inputs and outputs are goint to be refactor to 15x100 for the inputs and 30x30000 for the outputs to a total of 2.299 million records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "input_window_size = 15\n",
    "output_window_size = 30\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Factor to reshape the dataset\n",
    "reshape_factor = 2 \n",
    "\n",
    "input_window_size = int(max_sent_length['question'] / reshape_factor)\n",
    "output_window_size = int(max_sent_length['answer'] / reshape_factor)\n",
    "\n",
    "def get_batch_inputs(batch, batch_size = 10):\n",
    "    train_inputs = list()\n",
    "    \n",
    "    for input_index in inputs_indexes[batch:batch + batch_size]:\n",
    "        train_input = list()   \n",
    "        \n",
    "        for index in input_index:\n",
    "            # Formates the input to the word2vec encoded format\n",
    "            train_input.append(model.wv[reverse_dictionary[index]])\n",
    "            \n",
    "        train_inputs.append(train_input[:input_window_size])\n",
    "        train_inputs.append(train_input[input_window_size:])\n",
    "    return train_inputs\n",
    "\n",
    "def get_batch_outputs(batch, batch_size = 10):\n",
    "    train_outputs = list()\n",
    "    train_targets = list()\n",
    "    \n",
    "    for output_index in outputs_indexes[batch:batch + batch_size]:\n",
    "        train_output = list()\n",
    "        train_target = list()\n",
    "        \n",
    "        for index in output_index:\n",
    "            # Formates the output to the one-hot-encode format\n",
    "            output_encoded = np.zeros((len(dictionary)), dtype=np.float32)\n",
    "            output_encoded[index] = 1\n",
    "            train_output.append(output_encoded)\n",
    "            \n",
    "            if index > 0:\n",
    "                # Formates the target to the one-hot-encode format\n",
    "                # Setted as index - 1 because it ignores the first <s>\n",
    "                target_encoded = np.zeros((len(dictionary)), dtype=np.float32)\n",
    "                target_encoded[index - 1] = 1\n",
    "                train_target.append(target_encoded)\n",
    "            \n",
    "        train_outputs.append(train_output[:output_window_size])\n",
    "        train_outputs.append(train_output[output_window_size:])\n",
    "        \n",
    "        train_targets.append(train_target[:output_window_size])\n",
    "        train_targets.append(train_target[output_window_size:])\n",
    "        \n",
    "    return train_outputs, train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15, 100)\n",
      "(2, 30, 30000)\n"
     ]
    }
   ],
   "source": [
    "input_example = get_batch_inputs(0, 1)\n",
    "output_example, _ = get_batch_outputs(0, 1)\n",
    "\n",
    "arr_input_example = np.asarray(input_example)\n",
    "arr_output_example = np.asarray(output_example)\n",
    "\n",
    "print(arr_input_example.shape)\n",
    "print(arr_output_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 16:52:49.817423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:50.132608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:50.133322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:50.135789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 16:52:50.137165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:50.137852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:50.138487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:51.181811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:51.182658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:51.182803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-26 16:52:51.182912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3215 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Input shape = 100\n",
    "input_shape = arr_input_example.shape[2]\n",
    "\n",
    "# Output shape = 30000\n",
    "output_shape = arr_output_example.shape[2]\n",
    "\n",
    "#Dimensionality\n",
    "dimensionality = 256\n",
    "\n",
    "#The batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 1000\n",
    "\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None, input_shape))\n",
    "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None, output_shape))\n",
    "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_shape, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#Model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "#Compiling\n",
    "training_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_target_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [112], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m outputs_data \u001b[38;5;241m=\u001b[39m get_batch_outputs(batch_record, data_batch_size)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#Training\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m training_model\u001b[38;5;241m.\u001b[39mfit([inputs_data, outputs_data], \u001b[43mdecoder_target_data\u001b[49m, batch_size \u001b[38;5;241m=\u001b[39m batch_size, epochs \u001b[38;5;241m=\u001b[39m epochs, validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     25\u001b[0m training_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_target_data' is not defined"
     ]
    }
   ],
   "source": [
    "num_records = len(dataset) * reshape_factor\n",
    "\n",
    "data_batch_size = 1000\n",
    "\n",
    "batch_records = math.ceil(num_records / data_batch_size)\n",
    "\n",
    "supported_batch_records = num_records / data_batch_size\n",
    "\n",
    "# Run for the batches \n",
    "for batch_record in range(batch_records + 1):\n",
    "    \n",
    "    # Validate for the limit size of the dataset\n",
    "    # Limit the last step not to exceed the data size\n",
    "    if batch_record > (num_records / data_batch_size):\n",
    "        input_batch_size = math.floor((supported_batch_records % 1) * data_batch_size)\n",
    "    \n",
    "    # Get the inputs\n",
    "    inputs_data = get_batch_inputs(batch_record, data_batch_size)\n",
    "    \n",
    "    # Get the outputs\n",
    "    outputs_data, target_data = get_batch_outputs(batch_record, data_batch_size)\n",
    "    \n",
    "    #Training\n",
    "    #training_model.fit([inputs_data, outputs_data], outputs_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "    #training_model.save('training_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_data, target_data = get_batch_outputs(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "\n",
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_data[0][0])\n",
    "print('')\n",
    "print(target_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
