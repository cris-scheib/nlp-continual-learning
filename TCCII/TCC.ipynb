{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 14:34:50.473451: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 14:34:51.259959: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-07 14:34:52.858224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-07 14:34:52.858349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-07 14:34:52.858361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Vocabulary\n",
    "\n",
    "First, we build the vocabulary dictionaries for the source and target. \n",
    "The vocabulary is the the file `vocab.txt` (generated in the other script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: [('<unk>', 0), ('<s>', 1), ('</s>', 2), ('.', 3), ('the', 4), (',', 5), ('a', 6), ('?', 7), ('to', 8), ('you', 9)]\n",
      "Reverse dictionary: [(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, '.'), (4, 'the'), (5, ','), (6, 'a'), (7, '?'), (8, 'to'), (9, 'you')]\n",
      "Vocabulary size:  30000\n"
     ]
    }
   ],
   "source": [
    "# Word string -> ID mapping\n",
    "dictionary = dict()\n",
    "\n",
    "with open('data/vocab.30K.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # disregard the new line aka `\\n`\n",
    "        dictionary[line[:-1]] = len(dictionary)\n",
    "        \n",
    "reverse_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
    "\n",
    "print('Dictionary:', list(dictionary.items())[:10], end = '\\n')\n",
    "print('Reverse dictionary:', list(reverse_dictionary.items())[:10], end = '\\n')\n",
    "print('Vocabulary size: ', len(dictionary), end = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "Here we load the data from the `dataset.csv` file (generated in the other script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Transform to lower, remove the new line and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerDataset(data):\n",
    "    return data.str.lower() \n",
    "    \n",
    "def cleanDataset(data):\n",
    "    return data.str.replace('/r/','')                  \\\n",
    "                .str.replace(')','', regex=False)      \\\n",
    "                .str.replace('(','', regex=False)      \\\n",
    "                .str.replace(']','', regex=False)      \\\n",
    "                .str.replace('[','', regex=False)      \\\n",
    "                .str.replace('!','')                   \\\n",
    "                .str.replace('\"','')                   \\\n",
    "    \n",
    "def paddDataset(data):\n",
    "    return data.str.replace(',', ' ,')                 \\\n",
    "                .str.replace('.',' . ', regex=False)    \\\n",
    "                .str.replace('?',' ?', regex=False)    \\\n",
    "                .str.replace('\\n',' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = nltk.tokenize.WhitespaceTokenizer()\n",
    "for column in dataset.columns:    \n",
    "    dataset[column] = lowerDataset(dataset[column]) \n",
    "    dataset[column] = cleanDataset(dataset[column])\n",
    "    dataset[column] = paddDataset(dataset[column])                                    \n",
    "    dataset[column] = dataset[column].apply(wt.tokenize)\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>[people, who, don't, want, children, ,, why, ?]</td>\n",
       "      <td>[it, only, took, me, about, 3, minutes, of, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405802</th>\n",
       "      <td>[getting, rid, of, my, porn, addiction]</td>\n",
       "      <td>[i'm, not, going, to, tell, you, that, you, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631117</th>\n",
       "      <td>[waiters/waitresses, of, reddit, ,, have, you,...</td>\n",
       "      <td>[blind, date, ., guy, made, a, joke, in, front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753087</th>\n",
       "      <td>[how, would, you, explain, what, a, casserole,...</td>\n",
       "      <td>[take, all, the, leftovers, in, your, fridge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54697</th>\n",
       "      <td>[you, are, stuck, in, an, elevator, with, the,...</td>\n",
       "      <td>[omg, please, dont, lock, me, in, an, elevator...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "2087      [people, who, don't, want, children, ,, why, ?]   \n",
       "405802            [getting, rid, of, my, porn, addiction]   \n",
       "631117  [waiters/waitresses, of, reddit, ,, have, you,...   \n",
       "753087  [how, would, you, explain, what, a, casserole,...   \n",
       "54697   [you, are, stuck, in, an, elevator, with, the,...   \n",
       "\n",
       "                                                   answer  \n",
       "2087    [it, only, took, me, about, 3, minutes, of, ba...  \n",
       "405802  [i'm, not, going, to, tell, you, that, you, sh...  \n",
       "631117  [blind, date, ., guy, made, a, joke, in, front...  \n",
       "753087  [take, all, the, leftovers, in, your, fridge, ...  \n",
       "54697   [omg, please, dont, lock, me, in, an, elevator...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Mean sentence length and standard deviation of sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central tendency, dispersion and shape of questions’s distribution\n",
      "count    1149819.000000\n",
      "mean          17.113906\n",
      "std            9.139078\n",
      "min            1.000000\n",
      "25%           11.000000\n",
      "50%           15.000000\n",
      "75%           21.000000\n",
      "max           82.000000\n",
      "Name: question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Central tendency, dispersion and shape of questions’s distribution')\n",
    "print(dataset['question'].str.len().describe().apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central tendency, dispersion and shape of answers’s distribution\n",
      "count    1149819.000000\n",
      "mean          54.452828\n",
      "std          844.371854\n",
      "min            0.000000\n",
      "25%           10.000000\n",
      "50%           22.000000\n",
      "75%           53.000000\n",
      "max       563680.000000\n",
      "Name: answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Central tendency, dispersion and shape of answers’s distribution')\n",
    "print(dataset['answer'].str.len().describe().apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the sentences to fixed length\n",
    "Update all sentences with a fixed size, to process the sentences as batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_length = {'question' : 30, 'answer': 60}\n",
    "\n",
    "def padding_sent(source):\n",
    "    padded = []\n",
    "    for tokens in dataset[source]: \n",
    "        # adding the start token\n",
    "        tokens.insert(0, '<s>')  \n",
    "\n",
    "        if len(tokens) >= max_sent_length[source]:\n",
    "            tokens = tokens[:(max_sent_length[source] - 1)]\n",
    "            tokens.append('</s>')\n",
    "\n",
    "        if len(tokens) < max_sent_length[source]:\n",
    "            tokens.extend(['</s>' for _ in range(max_sent_length[source] - len(tokens))])  \n",
    "\n",
    "        padded.append(tokens)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = padding_sent('question')\n",
    "answers = padding_sent('answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the reverse dataset\n",
    "The reverse dataset are going to be used to retrieve the decoder output to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reverse_dataset(source):\n",
    "    reverse_tokens = []\n",
    "    reverse_dataset = []\n",
    "    for tokens in source: \n",
    "        for token in tokens: \n",
    "            if token not in dictionary.keys():\n",
    "                reverse_tokens.append(dictionary['<unk>'])\n",
    "            else:\n",
    "                reverse_tokens.append(dictionary[token])\n",
    "        reverse_dataset.append(reverse_tokens)\n",
    "        reverse_tokens = []\n",
    "    return reverse_dataset\n",
    "\n",
    "inputs_indexes =  np.array(create_reverse_dataset(questions), dtype=np.int32)\n",
    "outputs_indexes =  np.array(create_reverse_dataset(answers), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "Use the Word2Vec to embed the input to a hight demention vector, that will keep the word relationships "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learns all the Word2Vec relationships fo the questions, answers and unkown words\n",
    "This code needs to be run just once\n",
    "\"\"\"\n",
    "\n",
    "model = Word2Vec(questions + answers + [['<unk>']], vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formating the inputs and outputs\n",
    "\n",
    "The dataset original format for inputs is 30x100 and for the outputs is 60x30000 for 1.149 million records, making the memory usage impracticable.\n",
    "\n",
    "The inputs and outputs are goint to be refactor to 15x100 for the inputs and 30x30000 for the outputs to a total of 2.299 million records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "input_window_size = 15\n",
    "output_window_size = 30\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Factor to reshape the dataset\n",
    "reshape_factor = 2 \n",
    "\n",
    "input_window_size = int(max_sent_length['question'] / reshape_factor)\n",
    "output_window_size = int(max_sent_length['answer'] / reshape_factor)\n",
    "\n",
    "def array_numpy(array):\n",
    "    return np.array(array, dtype=np.float32)\n",
    "\n",
    "def get_batch_inputs(batch, batch_size = 10):\n",
    "    train_inputs = list()\n",
    "    \n",
    "    for input_index in inputs_indexes[batch:batch + batch_size]:\n",
    "        train_input = list()   \n",
    "        \n",
    "        for index in input_index:\n",
    "            # Formates the input to the word2vec encoded format\n",
    "            train_input.append(model.wv[reverse_dictionary[index]])\n",
    "            \n",
    "        train_inputs.append(array_numpy(train_input[:input_window_size]))\n",
    "        train_inputs.append(array_numpy(train_input[input_window_size:]))\n",
    "    return array_numpy(train_inputs)\n",
    "\n",
    "def get_batch_outputs(batch, batch_size = 10):\n",
    "    train_outputs = list()\n",
    "    train_targets = list()\n",
    "    \n",
    "    for output_index in outputs_indexes[batch:batch + batch_size]:\n",
    "        train_output = list()\n",
    "        train_target = list()\n",
    "                \n",
    "        for timestep, index in enumerate(output_index):\n",
    "            # Formates the output to the one-hot-encode format\n",
    "            output_encoded = np.zeros(len(dictionary), dtype=np.float32)\n",
    "            output_encoded[index] = 1\n",
    "            train_output.append(output_encoded)\n",
    "            \n",
    "            # Formates the target to the one-hot-encode format\n",
    "            # Setted as index - 1 because it ignores the first <s>\n",
    "            if timestep > 0:\n",
    "                target_encoded = np.zeros(len(dictionary), dtype=np.float32)\n",
    "                target_encoded[output_index[timestep]] = 1.0\n",
    "                train_target.append(target_encoded)\n",
    "        \n",
    "        train_outputs.append(array_numpy(train_output[:output_window_size]))\n",
    "        train_outputs.append(array_numpy(train_output[output_window_size:]))\n",
    "        \n",
    "        #Add a </s> in the end of the target so len(output) == len(taget) \n",
    "        target_encoded = np.zeros(len(dictionary), dtype=np.float32)\n",
    "        target_encoded[output_index[-1]] = 1.0\n",
    "        train_target.append(target_encoded)\n",
    "                \n",
    "        train_targets.append(array_numpy(train_target[:output_window_size]))\n",
    "        train_targets.append(array_numpy(train_target[output_window_size:]))\n",
    "        \n",
    "    return array_numpy(train_outputs), array_numpy(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = get_batch_inputs(0, 1)\n",
    "output_example, target_example = get_batch_outputs(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:14:16.472317: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 117.19MiB (rounded to 122880000)requested by op Mul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-07-07 17:14:16.472388: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2023-07-07 17:14:16.472427: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 43, Chunks in use: 43. 10.8KiB allocated for chunks. 10.8KiB in use in bin. 240B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472454: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472480: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.2KiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472503: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 1, Chunks in use: 0. 2.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472529: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 15, Chunks in use: 13. 63.5KiB allocated for chunks. 52.0KiB in use in bin. 52.0KiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472554: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 3, Chunks in use: 2. 33.0KiB allocated for chunks. 20.0KiB in use in bin. 20.0KiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472579: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 17.5KiB allocated for chunks. 17.5KiB in use in bin. 10.0KiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472601: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472628: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 351.8KiB allocated for chunks. 351.8KiB in use in bin. 351.6KiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472655: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 3, Chunks in use: 2. 514.2KiB allocated for chunks. 384.5KiB in use in bin. 384.4KiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472680: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 5, Chunks in use: 4. 2.02MiB allocated for chunks. 1.63MiB in use in bin. 1.46MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472703: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 3, Chunks in use: 2. 2.29MiB allocated for chunks. 1.57MiB in use in bin. 1.31MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472727: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 9, Chunks in use: 8. 9.00MiB allocated for chunks. 8.00MiB in use in bin. 7.92MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472749: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472770: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472791: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472817: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 2. 58.59MiB allocated for chunks. 58.59MiB in use in bin. 58.59MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472843: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 56.59MiB allocated for chunks. 56.59MiB in use in bin. 29.30MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472870: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 3, Chunks in use: 2. 299.34MiB allocated for chunks. 234.38MiB in use in bin. 234.38MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472907: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 4. 556.92MiB allocated for chunks. 556.92MiB in use in bin. 509.03MiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472932: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 4. 2.15GiB allocated for chunks. 2.15GiB in use in bin. 2.15GiB client-requested in use in bin.\n",
      "2023-07-07 17:14:16.472957: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 117.19MiB was 64.00MiB, Chunk State: \n",
      "2023-07-07 17:14:16.472995: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 64.97MiB | Requested Size: 1.00MiB | in_use: 0 | bin_num: 18, prev:   Size: 1.00MiB | Requested Size: 1.00MiB | in_use: 1 | bin_num: -1, next:   Size: 4.0KiB | Requested Size: 4.0KiB | in_use: 1 | bin_num: -1\n",
      "2023-07-07 17:14:16.473016: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 3337617408\n",
      "2023-07-07 17:14:16.473041: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000000 of size 1280 next 1\n",
      "2023-07-07 17:14:16.473064: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000500 of size 256 next 2\n",
      "2023-07-07 17:14:16.473084: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000600 of size 256 next 3\n",
      "2023-07-07 17:14:16.473104: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000700 of size 256 next 5\n",
      "2023-07-07 17:14:16.473122: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000800 of size 256 next 6\n",
      "2023-07-07 17:14:16.473141: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000900 of size 256 next 4\n",
      "2023-07-07 17:14:16.473160: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000a00 of size 256 next 13\n",
      "2023-07-07 17:14:16.473179: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000b00 of size 256 next 16\n",
      "2023-07-07 17:14:16.473198: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000c00 of size 256 next 22\n",
      "2023-07-07 17:14:16.473217: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000d00 of size 256 next 7\n",
      "2023-07-07 17:14:16.473236: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000e00 of size 256 next 12\n",
      "2023-07-07 17:14:16.473255: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14000f00 of size 256 next 35\n",
      "2023-07-07 17:14:16.473273: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001000 of size 256 next 36\n",
      "2023-07-07 17:14:16.473292: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001100 of size 256 next 37\n",
      "2023-07-07 17:14:16.473311: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001200 of size 256 next 38\n",
      "2023-07-07 17:14:16.473330: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001300 of size 256 next 52\n",
      "2023-07-07 17:14:16.473349: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001400 of size 256 next 53\n",
      "2023-07-07 17:14:16.473368: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001500 of size 256 next 54\n",
      "2023-07-07 17:14:16.473387: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001600 of size 256 next 55\n",
      "2023-07-07 17:14:16.473406: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001700 of size 256 next 57\n",
      "2023-07-07 17:14:16.473425: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001800 of size 256 next 58\n",
      "2023-07-07 17:14:16.473444: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001900 of size 256 next 59\n",
      "2023-07-07 17:14:16.473463: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001a00 of size 256 next 14\n",
      "2023-07-07 17:14:16.473483: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14001b00 of size 4096 next 15\n",
      "2023-07-07 17:14:16.473502: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14002b00 of size 256 next 18\n",
      "2023-07-07 17:14:16.473520: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14002c00 of size 256 next 24\n",
      "2023-07-07 17:14:16.473539: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14002d00 of size 256 next 28\n",
      "2023-07-07 17:14:16.473567: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14002e00 of size 256 next 29\n",
      "2023-07-07 17:14:16.473586: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14002f00 of size 256 next 32\n",
      "2023-07-07 17:14:16.473606: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14003000 of size 256 next 33\n",
      "2023-07-07 17:14:16.473625: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14003100 of size 256 next 34\n",
      "2023-07-07 17:14:16.473645: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14003200 of size 256 next 21\n",
      "2023-07-07 17:14:16.473665: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14003300 of size 4096 next 23\n",
      "2023-07-07 17:14:16.473684: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14004300 of size 120064 next 25\n",
      "2023-07-07 17:14:16.473706: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b14021800 of size 684544 next 8\n",
      "2023-07-07 17:14:16.473727: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b140c8a00 of size 409600 next 9\n",
      "2023-07-07 17:14:16.473746: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1412ca00 of size 1048576 next 10\n",
      "2023-07-07 17:14:16.473768: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1422ca00 of size 1048576 next 11\n",
      "2023-07-07 17:14:16.473788: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1432ca00 of size 1048576 next 17\n",
      "2023-07-07 17:14:16.473807: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1442ca00 of size 1048576 next 39\n",
      "2023-07-07 17:14:16.473827: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1452ca00 of size 4096 next 40\n",
      "2023-07-07 17:14:16.473846: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1452da00 of size 1048576 next 41\n",
      "2023-07-07 17:14:16.473866: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1462da00 of size 4096 next 42\n",
      "2023-07-07 17:14:16.473885: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b1462ea00 of size 59334656 next 27\n",
      "2023-07-07 17:14:16.473906: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b17ec4a00 of size 30720000 next 26\n",
      "2023-07-07 17:14:16.473926: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b19c10a00 of size 152551424 next 20\n",
      "2023-07-07 17:14:16.473947: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b22d8ca00 of size 122880000 next 19\n",
      "2023-07-07 17:14:16.473967: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b2a2bca00 of size 576000000 next 30\n",
      "2023-07-07 17:14:16.473987: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b4c80da00 of size 576000000 next 31\n",
      "2023-07-07 17:14:16.474007: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b6ed5ea00 of size 120064 next 43\n",
      "2023-07-07 17:14:16.474026: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b6ed7bf00 of size 409600 next 44\n",
      "2023-07-07 17:14:16.474046: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b6eddff00 of size 1048576 next 45\n",
      "2023-07-07 17:14:16.474066: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b6eedff00 of size 4096 next 46\n",
      "2023-07-07 17:14:16.474085: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b6eee0f00 of size 122880000 next 47\n",
      "2023-07-07 17:14:16.474105: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b76410f00 of size 1048576 next 48\n",
      "2023-07-07 17:14:16.474124: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b76510f00 of size 4096 next 49\n",
      "2023-07-07 17:14:16.474144: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b76511f00 of size 30720000 next 50\n",
      "2023-07-07 17:14:16.474163: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7825df00 of size 120064 next 51\n",
      "2023-07-07 17:14:16.474183: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7827b400 of size 1280 next 56\n",
      "2023-07-07 17:14:16.474203: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7827b900 of size 960000 next 102\n",
      "2023-07-07 17:14:16.474223: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b78365f00 of size 409600 next 84\n",
      "2023-07-07 17:14:16.474243: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b783c9f00 of size 409600 next 88\n",
      "2023-07-07 17:14:16.474262: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7842df00 of size 1048576 next 73\n",
      "2023-07-07 17:14:16.474282: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7852df00 of size 1048576 next 77\n",
      "2023-07-07 17:14:16.474301: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7862df00 of size 68124160 next 63\n",
      "2023-07-07 17:14:16.474321: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c725d00 of size 4096 next 83\n",
      "2023-07-07 17:14:16.474341: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c726d00 of size 256 next 114\n",
      "2023-07-07 17:14:16.474361: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7c726e00 of size 2304 next 93\n",
      "2023-07-07 17:14:16.474380: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c727700 of size 17920 next 91\n",
      "2023-07-07 17:14:16.474401: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c72bd00 of size 10240 next 64\n",
      "2023-07-07 17:14:16.474422: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c72e500 of size 256 next 75\n",
      "2023-07-07 17:14:16.474442: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c72e600 of size 256 next 90\n",
      "2023-07-07 17:14:16.474461: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c72e700 of size 256 next 94\n",
      "2023-07-07 17:14:16.474481: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c72e800 of size 4096 next 103\n",
      "2023-07-07 17:14:16.474501: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7c72f800 of size 5632 next 85\n",
      "2023-07-07 17:14:16.474521: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c730e00 of size 4096 next 106\n",
      "2023-07-07 17:14:16.474541: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7c731e00 of size 13312 next 65\n",
      "2023-07-07 17:14:16.474562: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c735200 of size 10240 next 66\n",
      "2023-07-07 17:14:16.474583: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c737a00 of size 4096 next 67\n",
      "2023-07-07 17:14:16.474603: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c738a00 of size 240128 next 76\n",
      "2023-07-07 17:14:16.474623: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7c773400 of size 762368 next 82\n",
      "2023-07-07 17:14:16.474643: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c82d600 of size 153600 next 89\n",
      "2023-07-07 17:14:16.474663: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c852e00 of size 256 next 95\n",
      "2023-07-07 17:14:16.474682: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c852f00 of size 256 next 105\n",
      "2023-07-07 17:14:16.474702: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853000 of size 256 next 98\n",
      "2023-07-07 17:14:16.474722: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853100 of size 256 next 104\n",
      "2023-07-07 17:14:16.474741: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853200 of size 256 next 80\n",
      "2023-07-07 17:14:16.474761: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853300 of size 256 next 68\n",
      "2023-07-07 17:14:16.474780: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853400 of size 256 next 70\n",
      "2023-07-07 17:14:16.474800: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853500 of size 256 next 107\n",
      "2023-07-07 17:14:16.474819: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853600 of size 256 next 74\n",
      "2023-07-07 17:14:16.474838: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c853700 of size 4096 next 79\n",
      "2023-07-07 17:14:16.474858: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c854700 of size 4096 next 115\n",
      "2023-07-07 17:14:16.474878: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7c855700 of size 6144 next 109\n",
      "2023-07-07 17:14:16.474897: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c856f00 of size 4096 next 110\n",
      "2023-07-07 17:14:16.474917: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9b7c857f00 of size 132864 next 92\n",
      "2023-07-07 17:14:16.474937: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c878600 of size 478976 next 78\n",
      "2023-07-07 17:14:16.474958: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b7c8ed500 of size 144000000 next 86\n",
      "2023-07-07 17:14:16.474978: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b85241900 of size 144000000 next 101\n",
      "2023-07-07 17:14:16.474998: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9b8db95d00 of size 576000000 next 62\n",
      "2023-07-07 17:14:16.475018: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9bb00e6d00 of size 576000000 next 97\n",
      "2023-07-07 17:14:16.475039: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9bd2637d00 of size 143426304 next 18446744073709551615\n",
      "2023-07-07 17:14:16.475058: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2023-07-07 17:14:16.475082: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 43 Chunks of size 256 totalling 10.8KiB\n",
      "2023-07-07 17:14:16.475105: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2023-07-07 17:14:16.475140: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 13 Chunks of size 4096 totalling 52.0KiB\n",
      "2023-07-07 17:14:16.475162: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 10240 totalling 20.0KiB\n",
      "2023-07-07 17:14:16.475183: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 17920 totalling 17.5KiB\n",
      "2023-07-07 17:14:16.475205: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 120064 totalling 351.8KiB\n",
      "2023-07-07 17:14:16.475227: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 153600 totalling 150.0KiB\n",
      "2023-07-07 17:14:16.475249: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 240128 totalling 234.5KiB\n",
      "2023-07-07 17:14:16.475270: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 409600 totalling 1.17MiB\n",
      "2023-07-07 17:14:16.475291: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 478976 totalling 467.8KiB\n",
      "2023-07-07 17:14:16.475313: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 684544 totalling 668.5KiB\n",
      "2023-07-07 17:14:16.475335: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 960000 totalling 937.5KiB\n",
      "2023-07-07 17:14:16.475356: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 8 Chunks of size 1048576 totalling 8.00MiB\n",
      "2023-07-07 17:14:16.475377: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 30720000 totalling 58.59MiB\n",
      "2023-07-07 17:14:16.475399: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 59334656 totalling 56.59MiB\n",
      "2023-07-07 17:14:16.475421: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 122880000 totalling 234.38MiB\n",
      "2023-07-07 17:14:16.475443: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 143426304 totalling 136.78MiB\n",
      "2023-07-07 17:14:16.475465: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 144000000 totalling 274.66MiB\n",
      "2023-07-07 17:14:16.475486: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 152551424 totalling 145.48MiB\n",
      "2023-07-07 17:14:16.475507: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 576000000 totalling 2.15GiB\n",
      "2023-07-07 17:14:16.475528: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 3.04GiB\n",
      "2023-07-07 17:14:16.475548: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 3337617408 memory_limit_: 3337617408 available bytes: 0 curr_region_allocation_bytes_: 6675234816\n",
      "2023-07-07 17:14:16.475578: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                      3337617408\n",
      "InUse:                      3267112448\n",
      "MaxInUse:                   3337601280\n",
      "NumAllocs:                       24560\n",
      "MaxAllocSize:                576000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-07-07 17:14:16.475620: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***************************************************_************************************************\n",
      "2023-07-07 17:14:16.477195: W tensorflow/core/framework/op_kernel.cc:1768] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [289], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m decoder_inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, output_shape))\n\u001b[1;32m     22\u001b[0m decoder_lstm \u001b[38;5;241m=\u001b[39m LSTM(dimensionality, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m decoder_outputs, decoder_state_hidden, decoder_state_cell \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m decoder_dense \u001b[38;5;241m=\u001b[39m Dense(output_shape, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m decoder_dense(decoder_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/base_rnn.py:612\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m full_input_spec\n\u001b[0;32m--> 612\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Remove the additional_specs from input spec and keep the rest. It\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# is important to keep since the input spec was populated by\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# build(), and will be reused in the stateful=True.\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "# Input shape = 100\n",
    "input_shape = input_example.shape[2]\n",
    "\n",
    "# Output shape = 30000\n",
    "output_shape = output_example.shape[2]\n",
    "\n",
    "#Dimensionality\n",
    "dimensionality = 256\n",
    "\n",
    "#The batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 600\n",
    "\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None, input_shape))\n",
    "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None, output_shape))\n",
    "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_shape, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#Model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "#Compiling\n",
    "training_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_records = len(dataset) * reshape_factor\n",
    "\n",
    "# data_batch_size = 1000\n",
    "\n",
    "# batch_records = math.ceil(num_records / data_batch_size)\n",
    "\n",
    "# supported_batch_records = num_records / data_batch_size\n",
    "\n",
    "# Run for the batches \n",
    "for batch_record in range(batch_records + 1):\n",
    "    \n",
    "    # Validate for the limit size of the dataset\n",
    "    # Limit the last step not to exceed the data size\n",
    "    if batch_record > (num_records / data_batch_size):\n",
    "        input_batch_size = math.floor((supported_batch_records % 1) * data_batch_size)\n",
    "    \n",
    "    # Get the inputs\n",
    "    inputs_data = get_batch_inputs(batch_record, data_batch_size)\n",
    "    \n",
    "    # Get the outputs\n",
    "    outputs_data, target_data = get_batch_outputs(batch_record, data_batch_size)\n",
    "    \n",
    "    #Training\n",
    "    #training_model.fit([inputs_data, outputs_data], outputs_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "    #training_model.save('training_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 15, 100)\n",
      "(200, 30, 30000)\n",
      "(200, 30, 30000)\n"
     ]
    }
   ],
   "source": [
    "inputs_data = get_batch_inputs(0,100)\n",
    "    \n",
    "outputs_data, target_data = get_batch_outputs(0,100)\n",
    "\n",
    "print(inputs_data.shape)\n",
    "print(outputs_data.shape)\n",
    "print(target_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.3291 - accuracy: 0.4992 - val_loss: 4.3018 - val_accuracy: 0.5542\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 3.3153 - accuracy: 0.4994 - val_loss: 4.3571 - val_accuracy: 0.5550\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 3.2950 - accuracy: 0.5008 - val_loss: 4.3329 - val_accuracy: 0.5542\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 3.2703 - accuracy: 0.4994 - val_loss: 4.3602 - val_accuracy: 0.5567\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 3.2541 - accuracy: 0.5019 - val_loss: 4.3320 - val_accuracy: 0.5558\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 3.2239 - accuracy: 0.5013 - val_loss: 4.3906 - val_accuracy: 0.5542\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 3.1901 - accuracy: 0.5013 - val_loss: 4.3449 - val_accuracy: 0.5542\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 3.1730 - accuracy: 0.5031 - val_loss: 4.3357 - val_accuracy: 0.5558\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 3.1360 - accuracy: 0.5033 - val_loss: 4.2915 - val_accuracy: 0.5508\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 3.0876 - accuracy: 0.5038 - val_loss: 4.2504 - val_accuracy: 0.5542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9da1d23f40>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.fit([inputs_data, outputs_data], target_data, batch_size = 10, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
