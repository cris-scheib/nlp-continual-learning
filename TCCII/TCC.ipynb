{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 17:21:45.597540: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 17:21:45.716261: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-20 17:21:46.231690: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-20 17:21:46.231792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-20 17:21:46.231799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean \n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, GRU, Dense, Embedding\n",
    "from keras.utils import  pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "Here we load the data from the `dataset.csv` file (generated in the other script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_online_learning_data():\n",
    "    return pd.read_csv('data/dataset-online-learning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocabulary():\n",
    "    vocabulary = list()\n",
    "    with open('data/vocab-30k.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            vocabulary.append(line.strip())\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Transform to lower, remove the new line and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_data(data):\n",
    "    return data.str.lower() \n",
    "    \n",
    "def clean_data(data):\n",
    "    return data.str.replace(',', ' , ')                \\\n",
    "                .str.replace('.',' . ', regex=False)  \\\n",
    "                .str.replace('?',' ? ', regex=False)   \\\n",
    "                .str.replace(\"''\",' ', regex=False)   \\\n",
    "                .str.replace(r\"(\\s)'|'(\\s)\",' ', regex=True) \\\n",
    "                .str.replace(r\"[^a-zA-Z0-9?'.,]+\",' ',regex=True)\n",
    "\n",
    "def get_data(online_learning=False):\n",
    "    if online_learning:\n",
    "        data = load_online_learning_data()\n",
    "    else:\n",
    "        data = load_data()\n",
    "    for column in data.columns:    \n",
    "        data[column] = lower_data(data[column])\n",
    "        data[column] = clean_data(data[column])\n",
    "    return shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Mean sentence length and standard deviation of sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_analysis(clean=True):\n",
    "    data = get_data()\n",
    "    if clean: \n",
    "        data = remove_outliers(data)\n",
    "    print('Central tendency, dispersion and shape of questions’s distribution')\n",
    "    print(data['question'].str.len().describe().apply(lambda x: format(x, 'f')))\n",
    "    print('-'*100)\n",
    "    print('Central tendency, dispersion and shape of answers’s distribution')\n",
    "    print(data['answer'].str.len().describe().apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print_data_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data):\n",
    "    return data[(data['question'].str.len() < 100) & (data['question'].str.len() > 10) & (data['answer'].str.len() < 200) & (data['answer'].str.len() > 10)]\n",
    "\n",
    "def padd_data(data):\n",
    "    data = data.assign(question = '<start> ' + data.question  + ' <end>')\n",
    "    data = data.assign(answer = '<start> ' + data.answer  + ' <end>')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.replace(',', ' , ')      \\\n",
    "                .replace('.',' . ')              \\\n",
    "                .replace('?',' ? ')              \\\n",
    "                .replace(\"''\",' ')               \\\n",
    "\n",
    "    sentence = re.sub(r\"(\\s)'|'(\\s)\",\" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9?'.,]+\",\" \", sentence)\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    vocabulary = load_vocabulary()\n",
    "    \n",
    "    sentence = [word if word in vocabulary else '<unk>' for word in sentence.split(' ')]\n",
    "\n",
    "    # Add a start and stop token to detect the start and end of the sequence\n",
    "    sentence = '<start> ' + ' '.join(sentence) + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUESTION_SIZE = 31\n",
    "MAX_ANSWER_SIZE = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "Removing the outliers and adding <start> and <end> for each question, awnser pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(online_learning=False):\n",
    "    dataset = remove_outliers(get_data(online_learning))\n",
    "    dataset = padd_data(dataset)\n",
    "    return dataset['question'].tolist(), dataset['answer'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing \n",
    "Tokenize the data, padd the sequence and create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenize(vocabulary):\n",
    "    tokenizer = Tokenizer(filters='!\"#$%&()*+-:;=@[\\\\]^_{|}~\\t')\n",
    "  \n",
    "    # Convert sequences into internal vocab\n",
    "    tokenizer.fit_on_texts(vocabulary)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer, max_len):\n",
    "\n",
    "    # Convert internal vocab to numbers\n",
    "    tensor = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "    # Pad the tensors to assign equal length to all the sequences\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', truncating='post',maxlen=max_len)\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the clean and formated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    " \n",
    "    questions, answers = create_dataset()\n",
    "    vocabulary = load_vocabulary()\n",
    "    \n",
    "    #Create the tokenizer for inputs and outputs\n",
    "    tokenizer = load_tokenize(vocabulary)\n",
    "    \n",
    "    questions_tensor = tokenize(questions, tokenizer, MAX_QUESTION_SIZE)\n",
    "    answers_tensor = tokenize(answers, tokenizer, MAX_ANSWER_SIZE)\n",
    "\n",
    "    return questions_tensor, answers_tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_tensor, answers_tensor, tokenizer = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test\n",
    "Split 80% of the data to train and 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test count: 463660\n",
      "Train count: 115915\n"
     ]
    }
   ],
   "source": [
    "max_length_input, max_length_target = questions_tensor.shape[1], answers_tensor.shape[1]\n",
    "input_train, input_test, target_train, target_test = train_test_split(questions_tensor, answers_tensor, test_size=0.2)\n",
    "\n",
    "print(\"Test count:\", len(input_train))\n",
    "print(\"Train count:\", len(input_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question; index to word mapping\n",
      "2 ----> <start>\n",
      "14 ----> what\n",
      "24 ----> do\n",
      "10 ----> you\n",
      "24 ----> do\n",
      "9 ----> to\n",
      "59 ----> get\n",
      "1524 ----> rid\n",
      "13 ----> of\n",
      "1870 ----> stress\n",
      "8 ----> ?\n",
      "3 ----> <end>\n",
      "\n",
      "Target awnser; index to word mapping\n",
      "2 ----> <start>\n",
      "7 ----> a\n",
      "975 ----> deep\n",
      "6077 ----> tissue\n",
      "6519 ----> massage\n",
      "4 ----> .\n",
      "4 ----> .\n",
      "4 ----> .\n",
      "13073 ----> ahhh\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(text, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, text.index_word[t]))\n",
    "      \n",
    "print(\"Input question; index to word mapping\")\n",
    "convert(tokenizer, input_train[0])\n",
    "print()\n",
    "print(\"Target awnser; index to word mapping\")\n",
    "convert(tokenizer, target_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_input_size = len(tokenizer.word_index) + 1\n",
    "vocab_target_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "# Train hyperparameter\n",
    "BUFFER_SIZE = len(input_train)\n",
    "steps_per_epoch = len(input_train)//BATCH_SIZE\n",
    "\n",
    "# Test hyperparameter\n",
    "TEST_BUFFER_SIZE = len(input_test)\n",
    "steps_per_epoch_test = len(input_test)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 17:27:05.338553: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-10-20 17:27:05.338591: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cristine): /proc/driver/nvidia/version does not exist\n",
      "2023-10-20 17:27:05.344694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((input_test, target_test)).shuffle(TEST_BUFFER_SIZE)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8, 31]), TensorShape([8, 96]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "\n",
    "        # Embed the vocab to a dense embedding \n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # GRU Layer\n",
    "        # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n",
    "        # used for the linear transformation of the recurrent state\n",
    "        self.gru = GRU(self.encoder_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # Encoder network comprises an Embedding layer followed by a GRU layer\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    # To initialize the hidden state\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (8, 31, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (8, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Mechanism\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (8, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (8, 31, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = Attention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # Used for attention\n",
    "        self.attention = Attention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # x shape == (batch_size, 1)\n",
    "        # hidden shape == (batch_size, max_length)\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "        # context_vector shape == (batch_size, hidden_size)\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (8, 30001)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_target_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer and loss functions\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# Loss function\n",
    "def loss_function(real, pred):\n",
    "\n",
    "    # Take care of the padding. Not all sequences are of equal length.\n",
    "    # If there's a '0' in the sequence, the loss is being nullified\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    # tf.GradientTape() -- record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        # dec_hidden is used by attention, hence is the same enc_hidden\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        # <start> token is the initial decoder input\n",
    "        dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "\n",
    "            # Pass enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Use teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    # As this function is called per batch, compute the batch_loss\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    # Get the model's variables\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    # Compute the gradients\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    # Update the variables of the model/network\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inp, targ, enc_hidden):\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    # dec_hidden is used by attention, hence is the same enc_hidden\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    # <start> token is the initial decoder input\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "\n",
    "        # Pass enc_output to the decoder\n",
    "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "        # Compute the loss\n",
    "        test_loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "        # Use teacher forcing\n",
    "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    # As this function is called per batch, compute the test_batch_loss\n",
    "    test_batch_loss = (test_loss / int(targ.shape[1]))\n",
    "\n",
    "    return test_batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ff4cffa60b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_dir, max_to_keep=10)\n",
    "checkpoint.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  7680256   \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,618,560\n",
      "Trainable params: 11,618,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  7680256   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 multiple                  7084032   \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  30751025  \n",
      "                                                                 \n",
      " attention_1 (Attention)     multiple                  2100225   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,615,538\n",
      "Trainable params: 47,615,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#EPOCHS = 1\n",
    "\n",
    "# Training and testing loop\n",
    "with tf.device('/cpu:0'):\n",
    "    for epoch in range(EPOCHS):\n",
    "                \n",
    "        # ============================= TRAIN PHASE ==================================\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Loop through the dataset\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "            \n",
    "            print(batch, (inp, targ))\n",
    "\n",
    "            # Call the train method\n",
    "            batch_loss = train_step(inp, targ, enc_hidden)\n",
    "\n",
    "            # Compute the loss (per batch)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "        # Save (checkpoint) the model every 2 epochs\n",
    "        #if (epoch + 1) % 2 == 0:\n",
    "        #    manager.save()\n",
    "\n",
    "\n",
    "        # Output the loss observed until that epoch\n",
    "        print('Train Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "        \n",
    "                    \n",
    "        # ============================= TEST PHASE ==================================\n",
    "        \n",
    "        # Initialize the hidden state\n",
    "        enc_test_hidden = encoder.initialize_hidden_state() \n",
    "        total_test_loss = 0\n",
    "\n",
    "        for (batch_test, (inp_test, targ_test)) in enumerate(dataset_test.take(steps_per_epoch_test)):\n",
    "\n",
    "            # Call the test method\n",
    "            batch_test_loss = test_step(inp_test, targ_test, enc_test_hidden)\n",
    "\n",
    "            # Compute the loss (per batch)\n",
    "            total_test_loss += batch_test_loss\n",
    "            \n",
    "        print('Test Epoch {} Loss {:.4f}'.format(epoch + 1, total_test_loss / steps_per_epoch_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate function -- similar to the training loop\n",
    "def evaluate(sentence):\n",
    "\n",
    "    # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n",
    "    attention_plot = np.zeros((max_length_target, max_length_input))\n",
    "\n",
    "    # Preprocess the sentence given\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # Fetch the indices concerning the words in the sentence and pad the sequence\n",
    "    inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_input,\n",
    "                                                         padding='post')\n",
    "    # Convert the inputs to tensors\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    prediction_percentages = []\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    # Loop until the max_length is reached for the target lang (ENGLISH)\n",
    "    for t in range(max_length_target):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        \n",
    "        # Store the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        # Get the prediction with the maximum attention\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        prediction_percentage = predictions[0].numpy()\n",
    "        prediction_percentages.append(prediction_percentage)\n",
    "        \n",
    "        # Append the token to the result\n",
    "        result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        # If <end> token is reached, return the result, input, and attention plot\n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot, prediction_percentages\n",
    "\n",
    "        # The predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    return result, sentence, attention_plot, prediction_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Function for plotting the loss values\n",
    "def plot_loss(loss_values, title=None):\n",
    "    plt.plot(loss_values)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.xlabel('Batches',fontsize=11)\n",
    "    plt.ylabel('Loss',fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.margins(x=0.01, y=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(sentence, print_out=False):\n",
    "    result, sentence, attention_plot, prediction_percentages = evaluate(sentence)\n",
    "    return result, attention_plot, prediction_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(expected, predicted):\n",
    "    expected = [expected.split()]\n",
    "    predicted = predicted.split()\n",
    "    return sentence_bleu(expected, predicted, smoothing_function=SmoothingFunction().method4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_precision(prediction):\n",
    "    standard_percentages = [np.std(percentage) for percentage in prediction]\n",
    "    return np.mean(np.array(standard_percentages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.removeprefix('<start>')\n",
    "    sentence = sentence.removesuffix('<end>')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: what are you doing tonight?\n",
      "Predicted awnser: no money for women to . <end> \n",
      "Predicted precision: 3.083693265914917\n"
     ]
    }
   ],
   "source": [
    "sentence = 'what are you doing tonight?'\n",
    "result, attention_plot, prediction_percentages = response(sentence)\n",
    "precision = prediction_precision(prediction_percentages)\n",
    "\n",
    "#Printing the result\n",
    "print('Input: %s' % (sentence))\n",
    "print('Predicted awnser: {}'.format(result))\n",
    "print('Predicted precision: {}'.format(precision))\n",
    "\n",
    "#Ploting the attention\n",
    "#attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "#plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ploting loss\n",
    "#loss_file = open(\"old_tests/loss_64.txt\", \"r\")\n",
    "loss_file = open(\"test_loss.txt\", \"r\")\n",
    "data = loss_file.read()\n",
    "data_loss_list = data.split(\"\\n\")\n",
    "loss_file.close()\n",
    "\n",
    "data_loss_list = [i for i in data_loss_list if i]\n",
    "data_loss = [float(i) for i in data_loss_list]\n",
    "\n",
    "data_loss_mean = list()\n",
    "for i in range(int(len(data_loss_list)/ 30)):\n",
    "    data_loss_mean.append(mean(data_loss[i*30:(i*30)+30]))\n",
    "    \n",
    "plot_loss(data_loss_mean, 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "Question:   what is the worst idea you've ever had ?  \n",
      "Real awnser:   getting drunk , and shooting my car windshield with a shotgun . . .  \n",
      "Predicted awnser:  . oh , you don't eat since after years before . just had a slightly so thought its ok isn't happy attack i hated it without even know who is how hard it goes into the gang because i'm 24 and the rock two guys are made it right next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "Precision:  3.2344437\n",
      "---------------\n",
      "\n",
      "---------------\n",
      "Question:   what do you wish someone would say to you ?  \n",
      "Real awnser:    i love you too .  \n",
      "Predicted awnser:  just wait in people are way to make me \n",
      "Precision:  4.0613174\n",
      "---------------\n",
      "\n",
      "---------------\n",
      "Question:   you could add 1 cm to anything , how would you cause the most destruction ?  \n",
      "Real awnser:   add 1cm to my penis , and destroy massive amounts of pussy with my 3cm monster  \n",
      "Predicted awnser:  tf when i am currently really gone ? \n",
      "Precision:  3.2083433\n",
      "---------------\n",
      "\n",
      "---------------\n",
      "Question:   what's the weirdest dt thing you have found in your own house ?  \n",
      "Real awnser:   what's a dt thing ?  \n",
      "Predicted awnser:  my finger ? \n",
      "Precision:  3.7326133\n",
      "---------------\n",
      "\n",
      "---------------\n",
      "Question:   which two countries would be amazing as a combined country ?  \n",
      "Real awnser:   germany and poland wait \n",
      "Predicted awnser:  growing up . \n",
      "Precision:  3.42516\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    index = random.randint(0,len(questions))\n",
    "    result, _, prediction_percentages = response(questions[index])\n",
    "    bleu = bleu_score(remove_tags(answers[index]), remove_tags(result))\n",
    "    print('\\n---------------')\n",
    "    print('Question: ', remove_tags(questions[index]))\n",
    "    print('Real awnser: ', remove_tags(answers[index]))\n",
    "    print('Predicted awnser: ', remove_tags(result))\n",
    "    print('Precision: ', prediction_precision(prediction_percentages))\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_steps(data, return_loss=False):\n",
    "    EPOCHS = 10\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        retrain_total_loss = 0\n",
    "             \n",
    "        # Loop through the data\n",
    "        for (batch, (inp, targ)) in enumerate(data.take(steps_per_epoch)):\n",
    "              \n",
    "            # Call the train method\n",
    "            retrain_batch_loss = train_step(inp, targ, enc_hidden)\n",
    "\n",
    "            # Compute the loss (per batch)\n",
    "            retrain_total_loss += retrain_batch_loss\n",
    "\n",
    "        # Save (checkpoint) the model every 2 epochs\n",
    "        #if (epoch + 1) % 2 == 0:\n",
    "            #manager.save()\n",
    "            \n",
    "    if return_loss:\n",
    "        return retrain_total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "    min_precision = 6\n",
    "    last_question = None\n",
    "    \n",
    "    def start_chat(self):\n",
    "        user_response = input(\"Hi, I'm a chatbot trained on dialogs. Would you like to chat with me?\\n\")\n",
    "    \n",
    "        if user_response in self.negative_responses:\n",
    "            print(\"Ok, have a great day!\")\n",
    "            return\n",
    "        self.chat(user_response)\n",
    "    \n",
    "    def chat(self, sentence):\n",
    "        while not self.make_exit(sentence):\n",
    "            if self.last_question is not None:\n",
    "                print(\"Learning ... \")\n",
    "                self.retrain(sentence)\n",
    "                self.last_question = None\n",
    "                sentence = input(\"What more can I help you with?\")\n",
    "            else:\n",
    "                sentence = input(self.generate_response(sentence))\n",
    "  \n",
    "    def generate_response(self, sentence):\n",
    "        result, attention_plot, prediction_percentages = response(sentence)\n",
    "        precision = prediction_precision(prediction_percentages)\n",
    "        if precision < self.min_precision:\n",
    "            self.last_question = sentence\n",
    "            return \"Sorry, I'm still learning, what could be a possible answer to this question?\"\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    def retrain(self, sentence):\n",
    "        retrain_question = preprocess_sentence(self.last_question)\n",
    "        retrain_answer = preprocess_sentence(sentence)\n",
    "\n",
    "        retrain_question_tensor = tokenize([retrain_question], tokenizer, MAX_QUESTION_SIZE)\n",
    "        retrain_answer_tensor = tokenize([retrain_answer], tokenizer, MAX_ANSWER_SIZE)\n",
    "\n",
    "        retrain_answer_tensors = np.append(retrain_answer_tensor, retrain_answer_tensor, axis=0)\n",
    "        for i in range(BATCH_SIZE - 2):\n",
    "            retrain_answer_tensors = np.append(retrain_answer_tensors, retrain_answer_tensor, axis=0)\n",
    "\n",
    "        newdata = tf.data.Dataset.from_tensor_slices((retrain_answer_tensors, retrain_answer_tensors)).shuffle(BUFFER_SIZE)\n",
    "        newdata = newdata.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        retrain_steps(newdata)\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def make_exit(self, sentence):\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in sentence:\n",
    "                print(\"Ok, have a great day!\")\n",
    "                return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chatbot = Chatbot()\n",
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatAutomation:\n",
    "    min_precision = 6\n",
    "       \n",
    "    def chat(self, sentence, response, print_info=True):\n",
    "                  \n",
    "        result, precision = self.generate_response(sentence)\n",
    "        retrain_loss = None\n",
    "        if precision < self.min_precision:\n",
    "            retrain_loss = self.retrain(sentence, response)\n",
    "        \n",
    "        if print_info:\n",
    "            self.print_info(sentence, response, result, precision, retrain_loss)\n",
    "            \n",
    "        return precision, retrain_loss\n",
    "    \n",
    "    def print_info(self, sentence, response, result, precision, retrain_loss):\n",
    "        print('\\n---------------')\n",
    "        print('Question: ', remove_tags(sentence))\n",
    "        print('Real awnser: ', remove_tags(response))\n",
    "        print('Predicted awnser: ', remove_tags(result))\n",
    "        print('Precision: ', precision)\n",
    "        print('Retrain Loss {:.4f}'.format(retrain_loss))\n",
    "        print('---------------')\n",
    "  \n",
    "    def generate_response(self, sentence):\n",
    "        result, attention_plot, prediction_percentages = response(sentence)\n",
    "        precision = prediction_precision(prediction_percentages)\n",
    "        return result, precision    \n",
    "    \n",
    "    def retrain(self, sentence, response):\n",
    "        retrain_question = preprocess_sentence(sentence)\n",
    "        retrain_answer = preprocess_sentence(response)\n",
    "        \n",
    "        retrain_question_tensor = tokenize([retrain_question], tokenizer, MAX_QUESTION_SIZE)\n",
    "        retrain_answer_tensor = tokenize([retrain_answer], tokenizer, MAX_ANSWER_SIZE)\n",
    "\n",
    "        retrain_answer_tensors = np.append(retrain_answer_tensor, retrain_answer_tensor, axis=0)\n",
    "        for i in range(BATCH_SIZE - 2):\n",
    "            retrain_answer_tensors = np.append(retrain_answer_tensors, retrain_answer_tensor, axis=0)\n",
    "\n",
    "        newdata = tf.data.Dataset.from_tensor_slices((retrain_answer_tensors, retrain_answer_tensors)).shuffle(BUFFER_SIZE)\n",
    "        newdata = newdata.batch(BATCH_SIZE, drop_remainder=True)\n",
    "                \n",
    "        retrain_loss = retrain_steps(newdata, return_loss=True)\n",
    "        \n",
    "        \n",
    "        return retrain_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_auto = ChatAutomation()\n",
    "new_data_questions, new_data_answers = create_dataset(online_learning=True)\n",
    "\n",
    "precisions = list()\n",
    "retrain_losses = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tf.Tensor(0.020552495, shape=(), dtype=float32)\n",
      "\n",
      "---------------\n",
      "Question:   do you use the playback speed adjustment feature on youtube ? if yes , what for ?  \n",
      "Real awnser:   do you use the playback speed adjustment feature on youtube ? if yes , what for ?  \n",
      "Predicted awnser:  it's allergic \n",
      "Precision:  2.733448\n",
      "Retrain Loss 0.0206\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    index = random.randint(0,len(new_data_questions))\n",
    "    \n",
    "    question = new_data_questions[index]\n",
    "    answers = new_data_questions[index]\n",
    "    \n",
    "    \n",
    "    precision, retrain_loss = chat_auto.chat(question, answers, print_info=True)\n",
    "    precisions.append(precision)\n",
    "    retrain_losses.append(retrain_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
