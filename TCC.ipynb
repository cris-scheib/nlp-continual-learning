{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bcd51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python version:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86547416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 21 15:11:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   27C    P5    N/A /  75W |    159MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1538      G   /usr/lib/xorg/Xorg                 83MiB |\n",
      "|    0   N/A  N/A      1702      G   /usr/bin/gnome-shell               23MiB |\n",
      "|    0   N/A  N/A      3100      G   ...833906720136517076,131072       49MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4b4a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 15:12:03.725151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 15:12:04.505842: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-21 15:12:05.788865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 15:12:05.789092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 15:12:05.789115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pylab\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.utils import shuffle\n",
    "import word2vec\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4ff641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0dd06",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "[Dowload](https://nlp.stanford.edu/projects/nmt/):\n",
    "\n",
    "* English vocabulary: [`vocab.50K.en`](https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7635e",
   "metadata": {},
   "source": [
    "### Loading the Datasets and Building the Vocabulary\n",
    "\n",
    "First, we build the vocabulary dictionaries for the source and target (English) language. \n",
    "The vocabularies are found in the file `vocab.50K.en`(English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b2e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: [('<unk>', 0), ('<s>', 1), ('</s>', 2), ('the', 3), (',', 4), ('.', 5), ('of', 6), ('and', 7), ('to', 8), ('in', 9)]\n",
      "Reverse dictionary: [(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, 'the'), (4, ','), (5, '.'), (6, 'of'), (7, 'and'), (8, 'to'), (9, 'in')]\n",
      "Vocabulary size:  50000\n"
     ]
    }
   ],
   "source": [
    "# Word string -> ID mapping\n",
    "dictionary = dict()\n",
    "\n",
    "vocabulary_size = len(dictionary)\n",
    "with open('data/vocab.50K.en', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # disregard the new line aka `\\n`\n",
    "        dictionary[line[:-1]] = len(dictionary)\n",
    "        \n",
    "vocabulary_size = len(dictionary)\n",
    "reverse_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
    "\n",
    "print('Dictionary:', list(dictionary.items())[:10], end = '\\n')\n",
    "print('Reverse dictionary:', list(reverse_dictionary.items())[:10], end = '\\n')\n",
    "print('Vocabulary size: ', vocabulary_size, end = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1623674",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "Here we load the data from the dataset.csv file (generated in the other script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d59dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ecca3e",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Transform to lower, remove the new line and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42052bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "for column in dataset.columns:\n",
    "    dataset[column] = dataset[column].str.lower() \n",
    "    dataset[column] = dataset[column].str.replace(',', ' ,')  \\\n",
    "                                     .str.replace('.',' .', regex=False)   \\\n",
    "                                     .str.replace('?',' ?', regex=False)   \\\n",
    "                                     .str.replace(')','', regex=False)   \\\n",
    "                                     .str.replace('(','', regex=False)   \\\n",
    "                                     .str.replace('\"','')   \\\n",
    "                                     .str.replace('\\n',' ')\n",
    "    dataset[column] = dataset[column].apply(wt.tokenize)\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db800f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>998407</th>\n",
       "      <td>[how, will, you, fake, your, death, if, ever, ...</td>\n",
       "      <td>[no, need, i'm, already, dead, inside, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416655</th>\n",
       "      <td>[what's, a, deep, kids, movie, ?]</td>\n",
       "      <td>[james, and, the, giant, peach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169649</th>\n",
       "      <td>[psychiatric, of, reddit, ,, what's, the, symp...</td>\n",
       "      <td>[it's, called, dissociation, personality, diso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873296</th>\n",
       "      <td>[dear, vegetarian, redditors, ,, what, do, you...</td>\n",
       "      <td>[i, am, not, a, vegetarian, but, i, don't, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702974</th>\n",
       "      <td>[how, do, you, move, forward-, literally, and,...</td>\n",
       "      <td>[you, look, back, ,, and, everything, you, did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "998407  [how, will, you, fake, your, death, if, ever, ...   \n",
       "416655                  [what's, a, deep, kids, movie, ?]   \n",
       "169649  [psychiatric, of, reddit, ,, what's, the, symp...   \n",
       "873296  [dear, vegetarian, redditors, ,, what, do, you...   \n",
       "702974  [how, do, you, move, forward-, literally, and,...   \n",
       "\n",
       "                                                   answer  \n",
       "998407          [no, need, i'm, already, dead, inside, .]  \n",
       "416655                    [james, and, the, giant, peach]  \n",
       "169649  [it's, called, dissociation, personality, diso...  \n",
       "873296  [i, am, not, a, vegetarian, but, i, don't, eve...  \n",
       "702974  [you, look, back, ,, and, everything, you, did...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada21a8a",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Mean sentence length and standard deviation of sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68588d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Questions) Average sentence length:  17.101486059545056\n",
      "(Questions) Standard deviation of sentence length:  9.122891352194081\n",
      "(Answers) Average sentence length:  54.367627238247216\n",
      "(Answers) Standard deviation of sentence length:  843.0636308326157\n"
     ]
    }
   ],
   "source": [
    "print('(Questions) Average sentence length: ', dataset['question'].str.len().mean())\n",
    "print('(Questions) Standard deviation of sentence length: ', dataset['question'].str.len().std())\n",
    "\n",
    "print('(Answers) Average sentence length: ', dataset['answer'].str.len().mean())\n",
    "print('(Answers) Standard deviation of sentence length: ', dataset['answer'].str.len().std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe4985",
   "metadata": {},
   "source": [
    "### Update the sentences to fixed length\n",
    "Update all sentences with a fixed size, to process the sentences as batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f77928",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_length = {'question' : 30, 'answer': 70}\n",
    "\n",
    "def padding_sent(source):\n",
    "    padded = []\n",
    "    for tokens in dataset[source]: \n",
    "        # adding the start token\n",
    "        tokens.insert(0, '<s>')  \n",
    "\n",
    "        if len(tokens) >= max_sent_length[source]:\n",
    "            tokens = tokens[:(max_sent_length[source] - 1)]\n",
    "            tokens.append('</s>')\n",
    "\n",
    "        if len(tokens) < max_sent_length[source]:\n",
    "            tokens.extend(['</s>' for _ in range(max_sent_length[source] - len(tokens))])  \n",
    "\n",
    "        padded.append(tokens)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc61866",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = padding_sent('question')\n",
    "answers = padding_sent('answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924d3d3",
   "metadata": {},
   "source": [
    "### Create the reverse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ad51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reverse_dataset(source):\n",
    "    reverse_tokens = []\n",
    "    reverse_dataset = []\n",
    "    for tokens in source: \n",
    "        for token in tokens: \n",
    "            if token not in dictionary.keys():\n",
    "                reverse_tokens.append(dictionary['<unk>'])\n",
    "            else:\n",
    "                reverse_tokens.append(dictionary[token])\n",
    "        reverse_dataset.append(reverse_tokens)\n",
    "        reverse_tokens = []\n",
    "    return reverse_dataset\n",
    "\n",
    "train_inputs =  np.array(create_reverse_dataset(questions), dtype=np.int32)\n",
    "train_outputs =  np.array(create_reverse_dataset(answers), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467bf5ec",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c1c2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_cursors = [0 for _ in range(train_inputs.shape[0])]\n",
    "batch_size = 32\n",
    "embedding_size = 64\n",
    "steps = 80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e9857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "with window_size = 2:\n",
      "    batch: [['<s>', 'former', 'of', '<unk>'], ['<s>', '<unk>', 'favourite', 'light'], ['<s>', 'postal', 'of', '<unk>'], ['<s>', 'as', 'kid', ','], ['<s>', 'you', 'throw', '10000'], ['<s>', 'how', 'you', 'feel'], ['<s>', 'where', 'you', 'put'], ['<s>', 'when', 'the', 'absolute']]\n",
      "    labels: ['smokers', 'your', 'workers', 'a', 'can', 'would', 'do', 'was']\n",
      "Defining 4 embedding lookups representing each word in the context\n",
      "Stacked embedding size: [32, 64, 4]\n",
      "Reduced mean embedding size: [32, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 14:31:47.258978: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 14:31:47.306573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 14:31:47.369285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 14:31:47.369851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 14:31:47.802758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 14:31:47.802977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 14:31:47.803119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 14:31:47.803228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2606 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-03-20 14:31:47.809391: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 2000: 2.779788\n",
      "Average loss at step 4000: 1.444825\n",
      "Average loss at step 6000: 1.281724\n",
      "Average loss at step 8000: 1.185413\n",
      "Average loss at step 10000: 1.129574\n",
      "Nearest to should: did, constituent, would, husbands, Derrida, does, well, greetings,\n",
      "Nearest to -: ,, women, instead, fellow, cooled, cops, housed, Bible,\n",
      "Nearest to also: parents, dopo, deceiving, CAM, Elche, S.p.A., walked, leases,\n",
      "Nearest to The: Alejandro, presses, pioneered, Absolute, Berlaymont, devoid, Excellent, multiple,\n",
      "Nearest to these: 1821, sparking, satisfying, MacDonald, www.avaaz.org, Jo, collateral, Rhapsody,\n",
      "Nearest to us: <unk>, worst, for, indemnify, longest, apple, alright, ridiculous,\n",
      "Nearest to out: sleep, indelible, prayer, fell, live, all, vs, meu,\n",
      "Nearest to or: Poos, biocidal, parody, Multitude, object, decides, Immanuel, Link,\n",
      "Nearest to by: Advocates, GfK, Sealed, ERC, 3.7, jour, 6.30, tabling,\n",
      "Nearest to as: video, movie, person, Procchio, girl, scale, song, weird,\n",
      "Nearest to latest: Scouting, Vigilio, worst, comeback, architect, insult, undulating, Büro,\n",
      "Nearest to brought: how, bullied, lavatory, reverse, legislatures, Regiment, Angaben, Characteristic,\n",
      "Nearest to size: Terry, Retoucher, action, bronchitis, mythical, contemplated, Jakob, EFSF,\n",
      "Nearest to sound: untenable, Localization, Millions, scales, acknowledgment, sank, safest, painful,\n",
      "Nearest to Central: cabbage, dado, Synergy, Assault, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: metropolitan, nomads, jpeg, Hosting, Browsing, immune, said, OTHER,\n",
      "Nearest to independent: Probe, sectoral, Agora, ICEcat, Wegener, dodge, 24h, Inquiry,\n",
      "Nearest to land: SOUND, refinements, exchanger, supplanted, eutrophication, 307, endorse, went,\n",
      "Nearest to search: mainframe, chute, Ironforge, Lakeside, anger, sunburn, eagerness, relegated,\n",
      "Nearest to rates: Whether, aeronautics, magazin, Watts, dominate, Chess, skates, Suliban,\n",
      "Average loss at step 12000: 1.093283\n",
      "Average loss at step 14000: 1.067507\n",
      "Average loss at step 16000: 1.049263\n",
      "Average loss at step 18000: 1.047472\n",
      "Average loss at step 20000: 1.040354\n",
      "Nearest to should: would, did, can, realised, mysql, Espace, constituent, warming,\n",
      "Nearest to -: fellow, mall, ap, un, Bible, chefs, ,, walks,\n",
      "Nearest to also: walked, granted, parents, dopo, deceiving, hit, given, Of,\n",
      "Nearest to The: Alejandro, presses, pioneered, Absolute, Berlaymont, devoid, Excellent, emits,\n",
      "Nearest to these: 1821, collateral, satisfying, Rhapsody, MacDonald, Holstein, Jamaica, doorway,\n",
      "Nearest to us: <unk>, indemnify, longest, actual, appropriate, Coriantumr, overnight, winding,\n",
      "Nearest to out: fell, sleep, live, indelible, all, lived, prayer, meu,\n",
      "Nearest to or: Poos, decides, Multitude, object, adjournment, biocidal, inapplicable, parody,\n",
      "Nearest to by: Advocates, GfK, Sealed, sides, daran, moments, analyzed, 6.30,\n",
      "Nearest to as: Procchio, finished, CHILD, huge, Orion, girl, CDA, picking,\n",
      "Nearest to latest: worst, insult, Scouting, Vigilio, comeback, biggest, town, 2050,\n",
      "Nearest to brought: bullied, 17, tonight, want, how, lavatory, Characteristic, legislatures,\n",
      "Nearest to size: Retoucher, Terry, alerting, action, bronchitis, mythical, Na, rife,\n",
      "Nearest to sound: untenable, Localization, Worms, painful, safest, upmarket, harsh, grab,\n",
      "Nearest to Central: dado, Synergy, cabbage, Assault, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: metropolitan, nomads, jpeg, immune, Browsing, Mato, Hosting, Laotian,\n",
      "Nearest to independent: Probe, sectoral, Agora, 24h, biker, ICEcat, dodge, Stream,\n",
      "Nearest to land: SOUND, refinements, bored, endorse, eutrophication, custodians, went, very,\n",
      "Nearest to search: mainframe, Lakeside, Ironforge, linkages, eagerness, chute, lingua, instructors,\n",
      "Nearest to rates: aeronautics, Whether, magazin, renminbi, Chess, Watts, dominate, Suliban,\n",
      "Average loss at step 22000: 1.029904\n",
      "Average loss at step 24000: 1.034981\n",
      "Average loss at step 26000: 1.030983\n",
      "Average loss at step 28000: 1.020353\n",
      "Average loss at step 30000: 1.044761\n",
      "Nearest to should: would, did, can, will, mysql, could, warming, realised,\n",
      "Nearest to -: fellow, ,, Maritim, mall, ap, chemists, bosses, :,\n",
      "Nearest to also: walked, moved, granted, tasked, thoughts, fiber, dopo, deceiving,\n",
      "Nearest to The: presses, Alejandro, pioneered, Absolute, Berlaymont, devoid, Excellent, emits,\n",
      "Nearest to these: 1821, doorway, Holstein, routinely, Along, Rhapsody, F1, slowly,\n",
      "Nearest to us: indemnify, Coriantumr, <unk>, handicraft, emotional, equitably, tasting, usa,\n",
      "Nearest to out: fell, indelible, traveled, lived, 8, all, 6th, Benghazi,\n",
      "Nearest to or: Poos, Multitude, DVI, Payments, adjournment, gestellt, inapplicable, Nueva,\n",
      "Nearest to by: Advocates, GfK, on, realistic, Sealed, daran, boards, summoned,\n",
      "Nearest to as: CHILD, Orion, Procchio, certain, finished, Lopar, manner, child,\n",
      "Nearest to latest: worst, 2050, Scouting, darkest, Vigilio, onion, equivalent, comeback,\n",
      "Nearest to brought: 17, honestly, bullied, tonight, come, legislatures, want, tried,\n",
      "Nearest to size: Retoucher, alerting, Terry, college, Teatro, mythical, action, bronchitis,\n",
      "Nearest to sound: untenable, Localization, Worms, opposite, upmarket, heinous, event, painful,\n",
      "Nearest to Central: dado, Synergy, Assault, attenuation, ideale, Actions, referral, boarded,\n",
      "Nearest to supported: metropolitan, nomads, Mato, jpeg, Laotian, immune, Hosting, longtime,\n",
      "Nearest to independent: Probe, sectoral, Agora, Stream, periodically, 24h, biker, dodge,\n",
      "Nearest to land: bored, SOUND, refinements, went, endorse, homosexual, custodians, walking,\n",
      "Nearest to search: Lakeside, lingua, mainframe, Ironforge, relegated, awake, linkages, gravel,\n",
      "Nearest to rates: aeronautics, Whether, Suliban, renminbi, magazin, dominate, testimonials, Chess,\n",
      "Average loss at step 32000: 1.023770\n",
      "Average loss at step 34000: 1.041398\n",
      "Average loss at step 36000: 1.042854\n",
      "Average loss at step 38000: 1.027680\n",
      "Average loss at step 40000: 1.037344\n",
      "Nearest to should: would, can, did, will, could, mysql, detailled, Espace,\n",
      "Nearest to -: ,, ap, :, coaches, ethics, Maritim, 80th, bosses,\n",
      "Nearest to also: walked, involved, moved, arising, fiber, sirens, abducted, thoughts,\n",
      "Nearest to The: presses, Alejandro, pioneered, Absolute, Berlaymont, devoid, Excellent, colonized,\n",
      "Nearest to these: Doctor, F1, Along, routinely, contravention, 1821, 0044, www.avaaz.org,\n",
      "Nearest to us: indemnify, usa, emotional, handicraft, Coriantumr, spills, equitably, Friesland,\n",
      "Nearest to out: fell, indelible, 8, dipping, Benghazi, realised, Documentation, Bregenzerwald,\n",
      "Nearest to or: Poos, Multitude, Payments, Nueva, indemnity, gestellt, impatience, inapplicable,\n",
      "Nearest to by: Advocates, GfK, on, realistic, boards, dismayed, robbed, predefined,\n",
      "Nearest to as: Orion, CHILD, Teheran, Brähler, rebound, bind, Eugen, Lopar,\n",
      "Nearest to latest: onion, 2050, town, smallest, darkest, removing, Scouting, temperature,\n",
      "Nearest to brought: tried, honestly, 17, come, bullied, Sad, contrast, Characteristic,\n",
      "Nearest to size: alerting, Retoucher, mythical, Terry, Teatro, bronchitis, grinding, action,\n",
      "Nearest to sound: untenable, Localization, Worms, upmarket, heinous, opposite, event, Lisboa,\n",
      "Nearest to Central: dado, Synergy, Assault, attenuation, ideale, Actions, antioxidants, referral,\n",
      "Nearest to supported: metropolitan, nomads, Mato, Laotian, jpeg, immune, soundtracks, Browsing,\n",
      "Nearest to independent: Probe, 24h, Agora, periodically, 1923, sectoral, Stream, biker,\n",
      "Nearest to land: SOUND, bored, utmost, refinements, doorway, homosexual, went, custodians,\n",
      "Nearest to search: Lakeside, lingua, Ironforge, eagerness, relegated, shouting, linkages, gravel,\n",
      "Nearest to rates: aeronautics, Whether, renminbi, magazin, Or, Suliban, dominate, Chess,\n",
      "Average loss at step 42000: 1.040096\n",
      "Average loss at step 44000: 1.037316\n",
      "Average loss at step 46000: 1.070902\n",
      "Average loss at step 48000: 1.063058\n",
      "Average loss at step 50000: 1.059402\n",
      "Nearest to should: can, would, did, could, will, mysql, detailled, does,\n",
      "Nearest to -: ,, :, finances, ethics, Maritim, hillside, nightclub, coaches,\n",
      "Nearest to also: sirens, involved, walked, Pond, fiber, commentaries, Comparative, arising,\n",
      "Nearest to The: presses, Alejandro, pioneered, Absolute, colonized, devoid, Berlaymont, Excellent,\n",
      "Nearest to these: Doctor, Along, F1, 0044, Linguistic, Uniform, 50, contravention,\n",
      "Nearest to us: usa, emotional, insbesondere, handicraft, indemnify, spirit, <unk>, Coriantumr,\n",
      "Nearest to out: fell, Documentation, 8, indelible, soir, dipping, tempted, Benghazi,\n",
      "Nearest to or: Poos, Multitude, DVI, Payments, impatience, Valencia, Nueva, indemnity,\n",
      "Nearest to by: Advocates, GfK, on, dismayed, predefined, realistic, data, daran,\n",
      "Nearest to as: Orion, CHILD, rebound, Teheran, bind, Eugen, Brähler, Preliminary,\n",
      "Nearest to latest: onion, temperature, town, smallest, rarest, outcome, removing, meaning,\n",
      "Nearest to brought: tried, greatly, done, honestly, gotten, terrified, arguing, according,\n",
      "Nearest to size: Terry, alerting, Retoucher, bronchitis, Teatro, mythical, Plain, whet,\n",
      "Nearest to sound: untenable, upmarket, opposite, Localization, Worms, heat, flawed, heinous,\n",
      "Nearest to Central: dado, Synergy, Assault, attenuation, ideale, Actions, antioxidants, referral,\n",
      "Nearest to supported: metropolitan, nomads, Mato, soundtracks, Laotian, jpeg, Hosting, longtime,\n",
      "Nearest to independent: Probe, 1923, Agora, periodically, Stream, 24h, imprisoned, sectoral,\n",
      "Nearest to land: bored, SOUND, refinements, doorway, utmost, walking, homosexual, went,\n",
      "Nearest to search: Lakeside, relegated, eagerness, recent, shouting, monsoon, Ironforge, lingua,\n",
      "Nearest to rates: aeronautics, Whether, Or, magazin, Chess, partner, renminbi, dominate,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 52000: 1.066826\n",
      "Average loss at step 54000: 1.067815\n",
      "Average loss at step 56000: 1.074104\n",
      "Average loss at step 58000: 1.076034\n",
      "Average loss at step 60000: 1.071978\n",
      "Nearest to should: can, would, did, could, will, does, detailled, Vejer,\n",
      "Nearest to -: ,, :, finances, nightclub, coaches, Maritim, hillside, 80th,\n",
      "Nearest to also: sirens, oral, involved, arising, commentaries, clic, visited, dopo,\n",
      "Nearest to The: Alejandro, presses, pioneered, colonized, Absolute, devoid, Berlaymont, Excellent,\n",
      "Nearest to these: Doctor, F1, Along, 0044, contravention, 50, Ideally, Linguistic,\n",
      "Nearest to us: usa, insbesondere, handicraft, emotional, jealousy, tumours, Friesland, indemnify,\n",
      "Nearest to out: Documentation, 8, soir, Exif, Byzantine, indelible, fell, tempted,\n",
      "Nearest to or: Poos, Valencia, DVI, impatience, Multitude, Payments, Nueva, zero,\n",
      "Nearest to by: Advocates, on, GfK, dismayed, predefined, data, realistic, daran,\n",
      "Nearest to as: Orion, Eugen, rebound, Teheran, CHILD, bind, Lopar, Preliminary,\n",
      "Nearest to latest: onion, rarest, town, simplest, removing, outcome, temperature, ultimate,\n",
      "Nearest to brought: tried, terrified, according, aspire, taught, fill, access, collect,\n",
      "Nearest to size: Terry, alerting, Teatro, bronchitis, grinding, Plain, nett, música,\n",
      "Nearest to sound: untenable, upmarket, flawed, heat, opposite, Worms, Localization, heinous,\n",
      "Nearest to Central: dado, Synergy, Assault, antioxidants, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: metropolitan, nomads, Mato, soundtracks, Laotian, jpeg, immune, longtime,\n",
      "Nearest to independent: Probe, 1923, Agora, periodically, Stream, imprisoned, sectoral, 24h,\n",
      "Nearest to land: bored, SOUND, doorway, homosexual, Gaudi, went, utmost, refinements,\n",
      "Nearest to search: Lakeside, person, eagerness, monsoon, thanks, recent, opportune, relegated,\n",
      "Nearest to rates: aeronautics, Or, partner, Whether, magazin, Chess, riders, renminbi,\n",
      "Average loss at step 62000: 1.067349\n",
      "Average loss at step 64000: 1.083989\n",
      "Average loss at step 66000: 1.085574\n",
      "Average loss at step 68000: 1.089473\n",
      "Average loss at step 70000: 1.085248\n",
      "Nearest to should: can, would, did, could, might, will, does, detailled,\n",
      "Nearest to -: ,, :, nightclub, finances, 80th, enthralled, coaches, NYC,\n",
      "Nearest to also: sirens, oral, Pond, commentaries, involved, arising, deepens, reviews,\n",
      "Nearest to The: colonized, Alejandro, pioneered, presses, Absolute, devoid, Berlaymont, Excellent,\n",
      "Nearest to these: F1, Doctor, Along, 50, contravention, Ideally, water-, loop,\n",
      "Nearest to us: usa, insbesondere, tumours, handicraft, jealousy, alterations, ze, bassist,\n",
      "Nearest to out: 8, Documentation, soir, Exif, ANSI, Byzantine, into, Kouchner,\n",
      "Nearest to or: Valencia, impatience, DVI, Multitude, Payments, zero, Poos, Belle,\n",
      "Nearest to by: Advocates, GfK, on, dismayed, predefined, data, Bowling, identically,\n",
      "Nearest to as: Orion, Eugen, rebound, Teheran, Preliminary, Lopar, bind, CHILD,\n",
      "Nearest to latest: onion, rarest, removing, outcome, earliest, shortest, simplest, newest,\n",
      "Nearest to brought: tried, aspire, collect, according, arguing, taught, done, terrified,\n",
      "Nearest to size: Teatro, grinding, música, alerting, Plain, nett, moroccan, audience,\n",
      "Nearest to sound: untenable, upmarket, flawed, opposite, Worms, regulars, Localization, convenient,\n",
      "Nearest to Central: dado, Synergy, Assault, antioxidants, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: metropolitan, Mato, attempted, soundtracks, hacked, proposed, nomads, bathrooms,\n",
      "Nearest to independent: Probe, hey, imprisoned, 1923, Agora, periodically, apparently, ΝΑΤΟ,\n",
      "Nearest to land: bored, doorway, SOUND, see, Gaudi, went, 7,000, Toward,\n",
      "Nearest to search: opportune, monsoon, thanks, eagerness, memorable, relegated, Lakeside, anger,\n",
      "Nearest to rates: aeronautics, Whether, Or, magazin, partner, Chess, riders, runaway,\n",
      "Average loss at step 72000: 1.090024\n",
      "Average loss at step 74000: 1.094442\n",
      "Average loss at step 76000: 1.099556\n",
      "Average loss at step 78000: 1.096344\n",
      "Average loss at step 80000: 1.113771\n",
      "Nearest to should: can, would, might, did, could, cant, Vejer, will,\n",
      "Nearest to -: ,, :, nightclub, finances, enthralled, NYC, Algeria, hillside,\n",
      "Nearest to also: sirens, oral, worry, arising, deepens, involved, craft, reviews,\n",
      "Nearest to The: colonized, Alejandro, presses, pioneered, Absolute, devoid, earn, Berlaymont,\n",
      "Nearest to these: F1, Along, Ideally, Doctor, 50, loop, contravention, water-,\n",
      "Nearest to us: usa, insbesondere, jealousy, bassist, tumours, ravaged, handicraft, united,\n",
      "Nearest to out: soir, Documentation, Exif, Apostle, Byzantine, 8, ANSI, into,\n",
      "Nearest to or: Valencia, DVI, Belle, impatience, leniency, Party, toch, Payments,\n",
      "Nearest to by: Advocates, GfK, on, predefined, dismayed, narrow, data, crossroad,\n",
      "Nearest to as: Eugen, Preliminary, Lopar, Teheran, Orion, quantitatively, rebound, Peaks,\n",
      "Nearest to latest: onion, rarest, temperature, earliest, outcome, removing, shortest, simplest,\n",
      "Nearest to brought: tried, taught, access, according, aspire, arguing, collect, extent,\n",
      "Nearest to size: audience, grinding, dangers, música, Teatro, euphemism, nett, downfall,\n",
      "Nearest to sound: untenable, flawed, upmarket, copied, normalise, regulars, Localization, Worms,\n",
      "Nearest to Central: dado, Synergy, antioxidants, Assault, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: Mato, proposed, attempted, nomads, Hosting, metropolitan, longtime, immune,\n",
      "Nearest to independent: Probe, 1923, Agora, Nespresso, ΝΑΤΟ, periodically, mattresses, hey,\n",
      "Nearest to land: bored, doorway, SOUND, 7,000, see, Toward, rebel, five,\n",
      "Nearest to search: opportune, anger, monsoon, memorable, buddies, relegated, thanks, shouting,\n",
      "Nearest to rates: aeronautics, Whether, magazin, Or, renminbi, runaway, Chess, Penken,\n",
      "Average loss at step 82000: 1.113116\n",
      "Average loss at step 84000: 1.120602\n",
      "Average loss at step 86000: 1.113074\n",
      "Average loss at step 88000: 1.122525\n",
      "Average loss at step 90000: 1.124206\n",
      "Nearest to should: can, might, would, could, did, does, Vejer, will,\n",
      "Nearest to -: ,, :, finances, nightclub, enthralled, NYC, satirical, Maritim,\n",
      "Nearest to also: sirens, oral, deepens, offended, arising, craft, Estimates, involved,\n",
      "Nearest to The: colonized, Alejandro, presses, Absolute, pioneered, earn, devoid, Berlaymont,\n",
      "Nearest to these: F1, Doctor, Along, 50, Ideally, contravention, 195, loop,\n",
      "Nearest to us: usa, insbesondere, united, ravaged, bassist, tumours, jealousy, ze,\n",
      "Nearest to out: soir, Documentation, ANSI, Byzantine, Exif, into, Kouchner, pickpockets,\n",
      "Nearest to or: Valencia, DVI, Belle, leniency, Party, impatience, toch, Payments,\n",
      "Nearest to by: Advocates, GfK, predefined, narrow, on, data, crossroad, dismayed,\n",
      "Nearest to as: Eugen, Preliminary, Teheran, quantitatively, archaeologist, Liebe, Orion, Peaks,\n",
      "Nearest to latest: rarest, onion, whole, earliest, temperature, newest, outcome, shortest,\n",
      "Nearest to brought: tried, taught, access, aspire, collect, according, purchased, motivated,\n",
      "Nearest to size: audience, dangers, spirit, downfall, location, Teatro, euphemism, música,\n",
      "Nearest to sound: untenable, upmarket, flawed, normalise, regulars, heinous, elephant, opposite,\n",
      "Nearest to Central: dado, antioxidants, Synergy, Assault, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: Mato, proposed, attempted, 80th, metropolitan, endowed, Hosting, longtime,\n",
      "Nearest to independent: Probe, 1923, 24h, Agora, imprisoned, hey, periodically, Nespresso,\n",
      "Nearest to land: bored, doorway, 7,000, rebel, SOUND, split, heat, Toward,\n",
      "Nearest to search: opportune, anger, monsoon, memorable, shouting, relegated, buddies, Lithuanian,\n",
      "Nearest to rates: Whether, aeronautics, magazin, Penken, renminbi, Or, runaway, Chess,\n",
      "Average loss at step 92000: 1.131230\n",
      "Average loss at step 94000: 1.129633\n",
      "Average loss at step 96000: 1.124089\n",
      "Average loss at step 98000: 1.144291\n",
      "Average loss at step 100000: 1.134075\n",
      "Nearest to should: can, might, would, could, does, did, will, detailled,\n",
      "Nearest to -: ,, :, nightclub, enthralled, --, finances, satirical, NYC,\n",
      "Nearest to also: sirens, deepens, oral, Clooney, Brett, Tamils, stitchers, Pond,\n",
      "Nearest to The: colonized, Alejandro, presses, Absolute, devoid, earn, Berlaymont, pioneered,\n",
      "Nearest to these: F1, 50, Ideally, Along, 195, contravention, Doctor, water-,\n",
      "Nearest to us: usa, insbesondere, united, bassist, ravaged, Plan, tumours, ze,\n",
      "Nearest to out: soir, Documentation, into, ANSI, Kouchner, Exif, Byzantine, Ones,\n",
      "Nearest to or: Valencia, DVI, Belle, leniency, Party, impatience, toch, restlessness,\n",
      "Nearest to by: Advocates, GfK, narrow, crossroad, predefined, on, tortured, dismayed,\n",
      "Nearest to as: Eugen, Preliminary, Teheran, archaeologist, quantitatively, Liebe, rebound, Orion,\n",
      "Nearest to latest: newest, earliest, rarest, temperature, ultimate, clown, longest, whole,\n",
      "Nearest to brought: tried, taught, collect, motivated, ruined, access, according, Fourteen,\n",
      "Nearest to size: audience, dangers, spirit, opposite, música, downfall, pinnacle, location,\n",
      "Nearest to sound: normalise, untenable, upmarket, heinous, flawed, elephant, Fathers, brew,\n",
      "Nearest to Central: dado, antioxidants, Synergy, Assault, attenuation, ideale, Actions, referral,\n",
      "Nearest to supported: Mato, attempted, proposed, 80th, Hosting, endowed, nomads, hacked,\n",
      "Nearest to independent: imprisoned, Probe, 1923, hey, 22, Agora, k, apparently,\n",
      "Nearest to land: bored, 7,000, doorway, split, heat, rebel, benefits, end,\n",
      "Nearest to search: opportune, anger, shouting, relegated, buddies, monsoon, resolution, memorable,\n",
      "Nearest to rates: aeronautics, Whether, renminbi, magazin, Penken, riders, Or, Suliban,\n"
     ]
    }
   ],
   "source": [
    "word2vec.define_data_and_hyperparameters(\n",
    "        train_inputs.shape[0], \n",
    "        max_sent_length['question'], \n",
    "        max_sent_length['answer'], \n",
    "        dictionary, \n",
    "        reverse_dictionary,  \n",
    "        train_inputs, \n",
    "        train_outputs, \n",
    "        embedding_size,\n",
    "        vocabulary_size)\n",
    "\n",
    "word2vec.print_some_batches()\n",
    "word2vec.define_word2vec_tensorflow(batch_size)\n",
    "word2vec.run_word2vec(batch_size, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bc51f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data\n",
      "['how', '<unk>', 'psychiatric', 'dear', 'how']\n",
      "['will', 'a', 'of', 'vegetarian', 'do']\n",
      "['you', 'deep', '<unk>', '<unk>', 'you']\n",
      "['fake', 'kids', ',', ',', 'move']\n",
      "['your', 'movie', '<unk>', 'what', '<unk>']\n",
      "['death', '?', 'the', 'do', 'literally']\n",
      "['if', '</s>', 'symptom', 'you', 'and']\n",
      "['ever', '</s>', 'of', 'pack', '<unk>']\n",
      "['needed', '</s>', 'multiple', 'for', 'from']\n",
      "['?', '</s>', 'personality', 'lunch', 'a']\n",
      "['</s>', '</s>', 'disorder', '?', 'bad']\n",
      "['</s>', '</s>', 'and', '</s>', 'track']\n",
      "['</s>', '</s>', 'what', '</s>', 'record']\n",
      "['</s>', '</s>', 'are', '</s>', '?']\n",
      "['</s>', '</s>', 'the', '</s>', 'serious']\n",
      "['</s>', '</s>', 'treatment', '</s>', '</s>']\n",
      "['</s>', '</s>', 'needed', '</s>', '</s>']\n",
      "['</s>', '</s>', 'for', '</s>', '</s>']\n",
      "['</s>', '</s>', 'it', '</s>', '</s>']\n",
      "['</s>', '</s>', '?', '</s>', '</s>']\n",
      "\n",
      "Target data batch\n",
      "['no', '<unk>', '<unk>', 'i', 'you']\n",
      "['need', 'and', 'called', 'am', 'look']\n",
      "['<unk>', 'the', '<unk>', 'not', 'back']\n",
      "['already', 'giant', 'personality', 'a', ',']\n",
      "['dead', 'peach', 'disorder', 'vegetarian', 'and']\n",
      "['inside', '</s>', '.', 'but', 'everything']\n",
      "['.', '</s>', 'the', 'i', 'you']\n",
      "['</s>', '</s>', '<unk>', '<unk>', 'did']\n",
      "['</s>', '</s>', 'will', 'ever', 'wrong']\n",
      "['</s>', '</s>', 'give', 'really', 'morally']\n",
      "['</s>', '</s>', 'you', 'bring', 'and']\n",
      "['</s>', '</s>', 'the', 'meat', 'literally']\n",
      "['</s>', '</s>', 'criteria', 'for', 'you']\n",
      "['</s>', '</s>', '.', 'lunch', 'do']\n",
      "['</s>', '</s>', '</s>', '.', 'the']\n",
      "['</s>', '</s>', '</s>', 'i', 'opposite']\n",
      "['</s>', '</s>', '</s>', 'take', '.']\n",
      "['</s>', '</s>', '</s>', '<unk>', 'if']\n",
      "['</s>', '</s>', '</s>', 'a', 'you']\n",
      "['</s>', '</s>', '</s>', 'lot', 'never']\n",
      "['</s>', '</s>', '</s>', 'as', 'wanna']\n",
      "['</s>', '</s>', '</s>', '<unk>', 'go']\n",
      "['</s>', '</s>', '</s>', 'cheap', 'back']\n",
      "['</s>', '</s>', '</s>', ',', 'to']\n",
      "['</s>', '</s>', '</s>', 'filling', 'the']\n",
      "['</s>', '</s>', '</s>', ',', 'person']\n",
      "['</s>', '</s>', '</s>', 'and', 'you']\n",
      "['</s>', '</s>', '</s>', 'microwaves', 'once']\n",
      "['</s>', '</s>', '</s>', 'really', 'were']\n",
      "['</s>', '</s>', '</s>', 'quick', ',']\n"
     ]
    }
   ],
   "source": [
    "class DataGenerator(object):\n",
    "\n",
    "    def __init__(self, batch_size, num_unroll, is_input, is_train):\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unroll = num_unroll\n",
    "        self._cursor = [0 for offset in range(self._batch_size)]\n",
    "        self._word_embeddings = np.load('embeddings.npy')\n",
    "        self._sent_ids = None\n",
    "        self._is_input = is_input\n",
    "        self._is_train = is_train\n",
    "\n",
    "    def next_batch(self, sent_ids):\n",
    "\n",
    "        sent_length = max_sent_length['question'] if self._is_input else max_sent_length['answer']\n",
    "\n",
    "        batch_data = np.zeros((self._batch_size, embedding_size), dtype=np.float32)\n",
    "        batch_labels = np.zeros((self._batch_size, vocabulary_size), dtype=np.float32)\n",
    "\n",
    "        for batch in range(self._batch_size):\n",
    "            sent_id = sent_ids[batch]\n",
    "            \n",
    "            if self._is_input:\n",
    "                sent_text = train_inputs[sent_id] if self._is_input else test_inputs[sent_id]\n",
    "            else:\n",
    "                sent_text = train_outputs[sent_id] if self._is_input else train_outputs[sent_id]\n",
    "            \n",
    "            batch_data[batch] = self._word_embeddings[sent_text[self._cursor[batch]],:]\n",
    "            batch_labels[batch] = np.zeros((vocabulary_size), dtype=np.float32)\n",
    "            batch_labels[batch, sent_text[self._cursor[batch] + 1]] = 1.0\n",
    "\n",
    "            self._cursor[batch] = (self._cursor[batch] + 1) % (sent_length - 1)\n",
    "\n",
    "        return batch_data,batch_labels\n",
    "\n",
    "    def unroll_batches(self,sent_ids):\n",
    "\n",
    "        if sent_ids is not None:\n",
    "            self._sent_ids = sent_ids\n",
    "            self._cursor = [0 for _ in range(self._batch_size)]\n",
    "        unroll_data, unroll_labels = [],[]\n",
    "\n",
    "        for unroll_ids in range(self._num_unroll):\n",
    "            data, labels = self.next_batch(self._sent_ids)\n",
    "            unroll_data.append(data)\n",
    "            unroll_labels.append(labels)\n",
    "        return unroll_data, unroll_labels, self._sent_ids\n",
    "\n",
    "    def reset_indices(self):\n",
    "        self._cursor = [0 for offset in range(self._batch_size)]\n",
    "\n",
    "dg = DataGenerator(batch_size=5, num_unroll=20, is_input=True, is_train=True)\n",
    "u_data, u_labels, _ = dg.unroll_batches([0,1,2,3,4])\n",
    "\n",
    "print('Input data')\n",
    "for _, lbl in zip(u_data,u_labels):\n",
    "    print([reverse_dictionary[w] for w in np.argmax(lbl,axis=1).tolist()])\n",
    "\n",
    "dg = DataGenerator(batch_size=5, num_unroll=30, is_input=False, is_train=True)\n",
    "u_data, u_labels, _ = dg.unroll_batches([0,1,2,3,4])\n",
    "\n",
    "print('\\nOutput data batch')\n",
    "for d_i,(_, lbl) in enumerate(zip(u_data,u_labels)):\n",
    "    print([reverse_dictionary[w] for w in np.argmax(lbl,axis=1).tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d461925",
   "metadata": {},
   "source": [
    "## Building the Model with TensorFlow\n",
    "\n",
    "Define the hyperparameters, the input/output placeholders, the LSTM/Output layer parameters, the LSTM/output calculations, and finally the optimization steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cca169",
   "metadata": {},
   "source": [
    "### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60e521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mat = np.load('embeddings.npy')\n",
    "input_size = emb_mat.shape[1]\n",
    "\n",
    "num_nodes = 128\n",
    "batch_size = 10\n",
    "\n",
    "encode_num_unrollings = 20\n",
    "decode_num_unrollings = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf386c",
   "metadata": {},
   "source": [
    "### Input / Output Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15751651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Encoder Data Placeholders\n",
      "Defining Decoder Data Placeholders\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "word_embeddings = tf.convert_to_tensor(value=emb_mat,name='embeddings')\n",
    "\n",
    "print('Defining Encoder Data Placeholders')\n",
    "encode_train_inputs = []\n",
    "\n",
    "for ui in range(encode_num_unrollings):\n",
    "    encode_train_inputs.append(tf.compat.v1.placeholder(tf.float32, shape=[batch_size,input_size],name='train_inputs_%d'%ui))\n",
    "\n",
    "print('Defining Decoder Data Placeholders')\n",
    "\n",
    "decode_train_inputs, decode_train_labels, decode_train_masks = [],[],[]\n",
    "\n",
    "for ui in range(decode_num_unrollings):\n",
    "    decode_train_inputs.append(tf.compat.v1.placeholder(tf.float32, shape=[batch_size,input_size],name='dec_train_inputs_%d'%ui))\n",
    "    decode_train_labels.append(tf.compat.v1.placeholder(tf.float32, shape=[batch_size,vocabulary_size], name = 'dec_train_labels_%d'%ui))\n",
    "    decode_train_masks.append(tf.compat.v1.placeholder(tf.float32, shape=[batch_size,1],name='dec_train_masks_%d'%ui))\n",
    "\n",
    "\n",
    "encode_test_input = [tf.compat.v1.placeholder(tf.float32, shape=[batch_size,input_size], name='test_input_%d'%ui) for ui in range(encode_num_unrollings)]\n",
    "decode_test_input = tf.nn.embedding_lookup(params=word_embeddings,ids=[dictionary['<s>']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52470c6",
   "metadata": {},
   "source": [
    "### Defining the Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a10af22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Model defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.compat.v1.variable_scope('Encoder'):\n",
    "\n",
    "    # Input gate\n",
    "    encoder_input_gate_x = tf.compat.v1.get_variable('input_gate_x', shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_input_gate_m = tf.compat.v1.get_variable('input_gate_m', shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_input_gate_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05, 0.05), name='input_gate_b')\n",
    "\n",
    "    # Forget gate\n",
    "    encoder_forget_gate_x = tf.compat.v1.get_variable('forget_gate_x', shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_forget_gate_m = tf.compat.v1.get_variable('forget_gate_m', shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_forget_gate_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05, 0.05), name='forget_gate_b')\n",
    "\n",
    "    # Candidate value (c~_t)\n",
    "    encoder_candidate_value_x = tf.compat.v1.get_variable('candidate_value_x', shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_candidate_value_m = tf.compat.v1.get_variable('candidate_value_m', shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_candidate_value_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05,0.05), name='candidate_value_b')\n",
    "\n",
    "    # Output gate\n",
    "    encoder_output_gate_x = tf.compat.v1.get_variable('output_gate_x', shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_output_gate_m = tf.compat.v1.get_variable('output_gate_m', shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    encoder_output_gate_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05,0.05), name='output_gate_b')\n",
    "\n",
    "    # Variáveis para salvar o resultado\n",
    "    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False, name='train_output')\n",
    "    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False, name = 'train_cell')\n",
    "\n",
    "    saved_test_output = tf.Variable(tf.zeros([batch_size, num_nodes]),trainable=False, name='test_output')\n",
    "    saved_test_state = tf.Variable(tf.zeros([batch_size, num_nodes]),trainable=False, name='test_cell')\n",
    "\n",
    "print('Encoder Model defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09954b00",
   "metadata": {},
   "source": [
    "### Defining the Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed93b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Model defined\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.variable_scope('Decoder'):\n",
    "\n",
    "    # Input gate\n",
    "    decoder_input_gate_x = tf.compat.v1.get_variable('input_gate_x',shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_input_gate_m = tf.compat.v1.get_variable('input_gate_m',shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_input_gate_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05, 0.05), name='input_gate_b')\n",
    "\n",
    "    # Forget gate\n",
    "    decoder_forget_gate_x = tf.compat.v1.get_variable('forget_gate_x', shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_forget_gate_m = tf.compat.v1.get_variable('forget_gate_m', shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_forget_gate_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05, 0.05), name='forget_gate_b')\n",
    "\n",
    "    # Candidate value (c~_t)\n",
    "    decoder_candidate_value_x = tf.compat.v1.get_variable('candidate_value_x', shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_candidate_value_m = tf.compat.v1.get_variable('candidate_value_m', shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_candidate_value_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05,0.05), name='candidate_value_b')\n",
    "\n",
    "    # Output gate\n",
    "    decoder_output_gate_x = tf.compat.v1.get_variable('output_gate_x',shape=[input_size, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_output_gate_m = tf.compat.v1.get_variable('output_gate_m',shape=[num_nodes, num_nodes], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    decoder_output_gate_b = tf.Variable(tf.random.uniform([1, num_nodes],-0.05,0.05),name='output_gate_b')\n",
    "\n",
    "    # Softmax Classifier\n",
    "    w = tf.compat.v1.get_variable('softmax_weights',shape=[num_nodes, vocabulary_size], initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "    b = tf.Variable(tf.random.uniform([vocabulary_size],-0.05,-0.05),name='softmax_bias')\n",
    "    \n",
    "print('Decoder Model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416ba0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
