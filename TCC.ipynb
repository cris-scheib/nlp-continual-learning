{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bcd51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python version:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86547416",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa4b4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pylab\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.utils import shuffle\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0dd06",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "[Dowload](https://nlp.stanford.edu/projects/nmt/):\n",
    "\n",
    "* English vocabulary: [`vocab.50K.en`](https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7635e",
   "metadata": {},
   "source": [
    "### Loading the Datasets and Building the Vocabulary\n",
    "\n",
    "First, we build the vocabulary dictionaries for the source and target (English) language. \n",
    "The vocabularies are found in the file `vocab.50K.en`(English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b2e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: [('<unk>', 0), ('<s>', 1), ('</s>', 2), ('the', 3), (',', 4), ('.', 5), ('of', 6), ('and', 7), ('to', 8), ('in', 9)]\n",
      "Reverse dictionary: [(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, 'the'), (4, ','), (5, '.'), (6, 'of'), (7, 'and'), (8, 'to'), (9, 'in')]\n",
      "Vocabulary size:  50000\n"
     ]
    }
   ],
   "source": [
    "# Word string -> ID mapping\n",
    "dictionary = dict()\n",
    "\n",
    "vocabulary_size = len(dictionary)\n",
    "with open('data/vocab.50K.en', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # disregard the new line aka `\\n`\n",
    "        dictionary[line[:-1]] = len(dictionary)\n",
    "        \n",
    "vocabulary_size = len(dictionary)\n",
    "reverse_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
    "\n",
    "print('Dictionary:', list(dictionary.items())[:10], end = '\\n')\n",
    "print('Reverse dictionary:', list(reverse_dictionary.items())[:10], end = '\\n')\n",
    "print('Vocabulary size: ', vocabulary_size, end = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1623674",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "Here we load the data from the dataset.csv file (generated in the other script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d59dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ecca3e",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Transform to lower, remove the new line and the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42052bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7254/562453711.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace('.',' .')   \\\n",
      "/tmp/ipykernel_7254/562453711.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  .str.replace('?',' ?')   \\\n"
     ]
    }
   ],
   "source": [
    "wt = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "for column in dataset.columns:\n",
    "    dataset[column] = dataset[column].str.lower() \n",
    "    dataset[column] = dataset[column].str.replace(',', ' ,')  \\\n",
    "                                     .str.replace('.',' .')   \\\n",
    "                                     .str.replace('?',' ?')   \\\n",
    "                                     .str.replace('\\n',' ')\n",
    "    dataset[column] = dataset[column].apply(wt.tokenize)\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db800f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155936</th>\n",
       "      <td>[men, of, reddit, ,, do, you, trim, your, armp...</td>\n",
       "      <td>[yes, ., it's, less, stinky, and, i, think, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587712</th>\n",
       "      <td>[redditors, ,, what, is, one, thing, you, are,...</td>\n",
       "      <td>[\"i've, never, been, much, for, sports, but, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113971</th>\n",
       "      <td>[hikers, and, campers, of, reddit, ,, what, is...</td>\n",
       "      <td>[my, brother, and, i, were, out, in, a, three-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222731</th>\n",
       "      <td>[reddit, parents:, what, do, do, when, a, care...</td>\n",
       "      <td>[\"tell, him, you, don't, want, your, kid, span...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061648</th>\n",
       "      <td>[is, there, a, commercial, that, you, hate, so...</td>\n",
       "      <td>[education, connection, ., i, fucking, hate, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  question  \\\n",
       "155936   [men, of, reddit, ,, do, you, trim, your, armp...   \n",
       "587712   [redditors, ,, what, is, one, thing, you, are,...   \n",
       "1113971  [hikers, and, campers, of, reddit, ,, what, is...   \n",
       "222731   [reddit, parents:, what, do, do, when, a, care...   \n",
       "1061648  [is, there, a, commercial, that, you, hate, so...   \n",
       "\n",
       "                                                    answer  \n",
       "155936   [yes, ., it's, less, stinky, and, i, think, it...  \n",
       "587712   [\"i've, never, been, much, for, sports, but, o...  \n",
       "1113971  [my, brother, and, i, were, out, in, a, three-...  \n",
       "222731   [\"tell, him, you, don't, want, your, kid, span...  \n",
       "1061648  [education, connection, ., i, fucking, hate, t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada21a8a",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Mean sentence length and standard deviation of sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68588d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(Questions) Average sentence length: ', dataset['question'].str.len().mean())\n",
    "print('(Questions) Standard deviation of sentence length: ', dataset['question'].str.len().std())\n",
    "\n",
    "print('(Answers) Average sentence length: ', dataset['answer'].str.len().mean())\n",
    "print('(Answers) Standard deviation of sentence length: ', dataset['answer'].str.len().std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe4985",
   "metadata": {},
   "source": [
    "### Update the sentences to fixed length\n",
    "Update all sentences with a fixed size, to process the sentences as batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum sentence length\n",
    "max_sent_length = {'question' : 30, 'answer': 70}\n",
    "\n",
    "for column in dataset.columns:\n",
    "    for tokens in dataset[column]: \n",
    "        \n",
    "        # adding the start token\n",
    "        tokens.insert(0, '<s>')\n",
    "        \n",
    "        if len(tokens) >= max_sent_length[column]:\n",
    "            tokens = tokens[:max_sent_length[column] - 1]\n",
    "            tokens.append('</s>')\n",
    "            \n",
    "        if len(tokens) < max_sent_length[column]:\n",
    "            tokens.extend(['</s>' for _ in range(max_sent_length[column] - len(tokens))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d67c33d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Word2Vec.__init__() got an unexpected keyword argument 'iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43malldata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m        \n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39minit_sims(replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Word2Vec.__init__() got an unexpected keyword argument 'iter'"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(alldata,\n",
    "                 sg=1,           \n",
    "                 window=3,       \n",
    "                 min_count=1,     \n",
    "                 workers=4,       \n",
    "                 iter=1)        \n",
    "model.init_sims(replace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d504ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
